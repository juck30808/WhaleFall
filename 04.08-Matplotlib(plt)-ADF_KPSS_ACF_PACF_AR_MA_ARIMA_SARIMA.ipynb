{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/Customers_in_a_Shop.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9q/486czkcn7lv5v0hwbt71twdc0000gn/T/ipykernel_5169/1241525859.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input/Customers_in_a_Shop.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Customers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%Y-%m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/Customers_in_a_Shop.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('input/Customers_in_a_Shop.csv',header=None)\n",
    "data.columns = ['Date','Customers']\n",
    "data['Date'] = pd.to_datetime(data['Date'],format=\"%Y-%m\")\n",
    "data = data.set_index('Date')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "\n",
    "我們有以下方法來處理時間序列數據中的缺失值。\n",
    "- (1) Mean Imputation 均值插補\n",
    "- (2) Last Observation Carried forward 最後一次觀察結轉\n",
    "- (3) Seasonal Interpolation 季節性插值\n",
    "- (4) Linear Interpolation 線性插值 (最常使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "plt.plot(data,color='black')\n",
    "plt.title(\"Number of Customers Visisting in a Ice Cream Shop since 1950\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Mean Imputation 均值插補"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "data['Customers_mean'] = data['Customers'].fillna(data['Customers'].mean())\n",
    "plt.plot(data['Customers_mean'],color='black')\n",
    "plt.title(\"Mean Imputation of Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Last Observation Carried forward 最後一次觀察結轉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "data['Customers_mean'] = data['Customers'].bfill()\n",
    "plt.plot(data['Customers_mean'],color='black')\n",
    "plt.title(\"Last Observation Carried Forward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Seasonal Interpolation 季節性插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find the dates where we have missing values\n",
    "data.index[data['Customers'].isnull()]\n",
    "data.loc['1960-03'].fillna((data['1949-03':'1959-03':12].sum())/data['1949-03':'1959-03':12].shape[0], inplace=True)\n",
    "data.loc['1954-06'].fillna((data['1949-06':'1953-06':12].sum())/data['1949-06':'1953-06':12].shape[0], inplace=True)\n",
    "data.loc['1951-07'].fillna((data['1949-07':'1950-07':12].sum())/data.loc['1949-07':'1950-07':12].shape[0], inplace=True)\n",
    "data.loc['1951-06'].fillna((data['1949-06':'1950-06':12].sum())/data['1949-06':'1950-06':12].shape[0], inplace=True)\n",
    "\n",
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "plt.plot(data['Customers'],color='black')\n",
    "plt.title(\"Seasonal Interpolation of Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Linear Interpolation 線性插值 (最常使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "data['Customers_linear']=data['Customers'].interpolate(method='linear')\n",
    "plt.plot(data['Customers_linear'],color='black')\n",
    "plt.title(\"Linear Interpolation of Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers 異常值偵測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity 平穩性\n",
    "平穩性意味著生成時間序列的過程的統計特性「不會隨時間變化」。 統計屬性是均值、方差和協方差，無論您觀察它們的時間如何，它們都是相同的。平穩性是一個重要的概念，因為平穩過程更容易分析和建模。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Customers_linear'].loc[(data['Customers_linear']>=700)] = 622\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plot 箱形圖\n",
    "它是一種標準化的數據分佈顯示方式。 任何小於 Q1-1.5IQR 或大於 Q3+1.5IQR 的數據點都被視為異常值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "sns.boxplot(data['Customers_linear'], color='brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Customers_linear'].sort_values(ascending = False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers treatment\n",
    "\n",
    "data['Customers_linear'].loc[(data['Customers_linear']>=700)] = 622\n",
    "# lets also check the null values again\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Dickey–Fuller test 擴張DF檢定  (ADF) \n",
    "\n",
    "（ADF 檢驗）是一種常用的統計檢驗，用於檢驗給定的時間序列是否平穩。 在分析序列的平穩性時，它是最常用的統計檢驗之一。所得出之統計值必為負數，負越多越傾向於拒絕虛無假說。\n",
    "\n",
    "- p-value > 0.05：未能拒絕原假設（H0），數據有單位根且非平穩。\n",
    "- p-value <= 0.05：拒絕原假設（H0），數據沒有單位根並且是平穩的。\n",
    "\n",
    "p 值為 1 且其值大於 0.05 ，因此無法拒絕原假設。 因此，數據具有單位根並且是非平穩的平均值不是平穩的。方差隨時間波動。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(data['Customers_linear'], autolag='AIC')\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'n_lags: {result[1]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "for key, value in result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kwiatkowski-Phillips-Schmidt-Shin 單根檢定（KPSS unit root test）\n",
    "\n",
    "(KPSS) 檢驗確定時間序列是圍繞均值或線性趨勢平穩，還是由於單位根而非平穩。 平穩時間序列是統計屬性（如均值和方差）隨時間保持不變的時間序列。對於 KPSS 測試，\n",
    "\n",
    "- 零假設(Null Hypothesis)：當 p 值 >0.05 時序列是平穩的\n",
    "- 替代假設 (Alternate Hypothesis)：當 p 值 <= 0.5 時，序列不是平穩的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading kpss from statsmodel\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "result = kpss(data['Customers_linear'])\n",
    "print(f'KPSS Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'num lags: {result[2]}')\n",
    "print('Critial Values:')\n",
    "for key, value in result[3].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Stationary to Stationary Series 非平穩轉換到平穩序列\n",
    "有兩種工具可以將非平穩序列轉換為平穩序列。\n",
    "\n",
    "- 1.Transformation 轉型\n",
    "- 2.Differencing 差分\n",
    "\n",
    "差分工具用於使時間序列的均值保持不變。 這意味著它從系列中刪除了趨勢。\n",
    "\n",
    "差分意味著計算連續觀察之間的差異。 差分通過從序列中去除趨勢來穩定時間序列的均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Cox Transformation 轉型\n",
    "Box Cox Transformation 是一種將非正態因變量轉換為正態形狀的方法。 正態性是許多統計技術的重要假設； 如果您的數據不正常，應用 Box-Cox 意味著您可以運行更多的測試。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "data_boxcox = pd.Series(boxcox(data['Customers_linear'],lmbda=0),index=data.index)\n",
    "plt.plot(data_boxcox, label=\"After Box Cox Transformation\")\n",
    "plt.legend()\n",
    "plt.title(\"Number of Customers Visisting in a Ice Cream Shop since 1950\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing 差分\n",
    "\n",
    "差分通過消除時間序列水平的變化來穩定時間序列的平均值，從而消除（或減少）趨勢和季節性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_boxcox_difference= pd.Series(data_boxcox-data_boxcox.shift(), index=data.index)\n",
    "data_boxcox_difference.dropna(inplace=True)\n",
    "plt.plot(data_boxcox_difference, label=\"After Box Cox Transformation and Differencing\")\n",
    "plt.legend()\n",
    "plt.title(\"Number of Customers Visisting in a Ice Cream Shop since 1950\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Correlation function 自相關函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Correleation Function 自相關函數 (ACF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading and plotting acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(data_boxcox_difference, ax=plt.gca(), lags=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Auto Correleation Function 偏自相關函數 (PACF)\n",
    "偏自相關函數 (PACF) 給出了平穩時間序列與其自身滯後值的偏相關，在所有較短的滯後處對時間序列的值進行回歸。它與不控制其他滯後的自相關函數形成對比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading and plottin pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plot_pacf(data_boxcox_difference, ax=plt.gca(), lags=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Train and Test dataset 拆分訓練和測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train = 115\n",
    "train = data.iloc[:length_train,:]\n",
    "test=data.iloc[length_train:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_boxcox = data_boxcox[:length_train]\n",
    "test_data_boxcox = data_boxcox[length_train:]\n",
    "train_data_boxcox_difference = data_boxcox_difference[:length_train-1]\n",
    "test_data_boxcox_difference = data_boxcox_difference[length_train-1:]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.AutoRegressive Model 自回歸模型 (AR)\n",
    "\n",
    "統計上一種處理時間序列的方法，用同一變數例如 x 的之前各期，亦即 x1 至x(t-1) 來預測本期 x(t) 的表現，並假設它們為一線性關係。因為這是從線性迴歸發展而來，只是不用 x 預測 y，而是用 x 預測 x（自己）；所以叫做自迴歸。回歸模型將未來觀察預測為一個或多個過去觀察的線性回歸。\n",
    "自迴歸模型被廣泛運用在經濟學、資訊學、自然現象的預測上。自回歸模型方程為\n",
    "\n",
    "y(t) = β_0 + β_1 y(t-2) + β_2 y(t-4) + β_3 y(t-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model_ar = ARIMA(train_data_boxcox_difference, order=(1,0,0))\n",
    "model_fit = model_ar.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover Original Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ar_new = data_boxcox_difference.copy()\n",
    "y_ar_new['ar_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                              data_boxcox_difference.index.max())\n",
    "y_ar_new['ar_forecast_boxcox'] = y_ar_new['ar_forecast_boxcox_difference'].cumsum()\n",
    "y_ar_new['ar_forecast_boxcox'] = y_ar_new['ar_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_ar_new['ar_forecast'] = np.exp(y_ar_new['ar_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Train, Test and Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_ar_new['ar_forecast'][test.index.min():], label = 'AR model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Auto regressive model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Moving average 移動平均 (MA)\n",
    " \n",
    "在統計學中是一種通過創建整個數據集中不同子集的一系列平均數來分析數據點的計算方法。給定一個數列和一個固定子集大小，移動平均數的第一個元素是由數列的初始固定子集的平均值得到的。然後通過「向前移位」修改子集，即排除序列的第一個數，並在子集中包含下一個值。移動平均通常與時間序列數據一起使用，以消除短期波動，突出長期趨勢或周期。短期和長期之間的閾值取決於應用，移動平均的參數將相應地設置。例如，它通常用於對財務數據進行技術分析，如股票價格、收益率或交易量。它也用於經濟學中研究國內生產總值、就業或其他宏觀經濟時間序列。\n",
    "\n",
    "數學上，移動平均是卷積的一種類型，因此它可以被看作是用於信號處理的低通濾波器的一個例子。當與非時間序列數據一起使用時，移動平均濾波器的頻率分量更高，但與時間沒有任何特定的聯繫，儘管通常暗含某種排序。簡單地看，它可以看作是把數據變得更平滑。數學方程式是：\n",
    "\n",
    "- y(t) = µ + φ(k)*ε(t-k)\n",
    "- µ 是系列的平均值\n",
    "- ε(t-k) 是過去的預測值\n",
    "- φ(k) 是與誤差值相關的權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model_ma = ARIMA(train_data_boxcox_difference, order=(0,0,7))\n",
    "model_fit = model_ma.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover Original Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ma_new = data_boxcox_difference.copy()\n",
    "y_ma_new['ma_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                              data_boxcox_difference.index.max())\n",
    "y_ma_new['ma_forecast_boxcox'] = y_ma_new['ma_forecast_boxcox_difference'].cumsum()\n",
    "y_ma_new['ma_forecast_boxcox'] = y_ma_new['ma_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_ma_new['ma_forecast'] = np.exp(y_ma_new['ma_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Train, Test and Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_ma_new['ma_forecast'][test.index.min():], label = 'MA model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moving Average regressive model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AutoRegressive Integrated Moving Average Model (ARIMA)\n",
    "\n",
    "差分整合移動平均自迴歸模型，時間序列預測分析方法之一。ARIMA（p，d，q）中，AR是\"自回歸\"，p為自回歸項數；MA為\"滑動平均\"，q為滑動平均項數，d為使之成為平穩序列所做的差分次數（階數）。「差分」一詞雖未出現在ARIMA的英文名稱中，卻是關鍵步驟。\n",
    "它使用 Box Cox 轉換時間序列，然後自己處理差異並從時間序列中刪除趨勢。我們需要使用三個參數：\n",
    "- p 是模型中的最高滯後\n",
    "- d 是使序列平穩的差分程度\n",
    "- q 是包含的過去錯誤項的數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "# model = ARIMA(train_data_boxcox, order=(5,1,2))\n",
    "# model_fit = model.fit()\n",
    "# print(model_fit.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_arima_new = data_boxcox_difference.copy()\n",
    "# y_arima_new['arima_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "#                                                                     data_boxcox_difference.index.max())\n",
    "# y_arima_new['arima_forecast_boxcox'] = y_arima_new['arima_forecast_boxcox_difference'].cumsum()\n",
    "# y_arima_new['arima_forecast_boxcox'] = y_arima_new['arima_forecast_boxcox'].add(data_boxcox[0])\n",
    "# y_arima_new['arima_forecast'] = np.exp(y_arima_new['arima_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Train, Test and Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(17,8))\n",
    "\n",
    "# plt.plot(train['Customers_linear'], label = 'Train')\n",
    "# plt.plot(test['Customers_linear'], label = 'Test')\n",
    "# plt.plot(y_arima_new['arima_forecast'][test.index.min():], label = 'ARiMA model')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title('Auto regressive Integrated Moving Average model')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal AutoRegressive Integrated Moving Average Model (SARIMA)\n",
    "\n",
    "季節性自回歸綜合移動平均模型 (SARIMA) 帶來了 ARIMA 模型的所有特徵以及季節性。在 SARIMA 中執行的關鍵元素是：\n",
    "- 對時間序列進行差分以使其平穩。\n",
    "- SARIMA 方程是過去觀察和過去誤差的線性組合。\n",
    "- 對時間序列執行季節性差分。\n",
    "- SARIMA 將未來季節性建模為過去季節性觀察結果和過去季節性誤差的線性組合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "model = SARIMAX(train_data_boxcox_difference, order=(1,1,1), seasonal_order=(1,1,1,6))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover Original Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sarima_new = data_boxcox_difference.copy()\n",
    "y_sarima_new['sarima_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                                      data_boxcox_difference.index.max())\n",
    "y_sarima_new['sarima_forecast_boxcox'] = y_sarima_new['sarima_forecast_boxcox_difference'].cumsum()\n",
    "y_sarima_new['sarima_forecast_boxcox'] = y_sarima_new['sarima_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_sarima_new['sarima_forecast'] = np.exp(y_sarima_new['sarima_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Train, Test and Forecasted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_sarima_new['sarima_forecast'][test.index.min():], label = 'SARIMA model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Seasonal Auto regressive Integrated Moving Average model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
