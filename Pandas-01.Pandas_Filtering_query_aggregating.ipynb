{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is pandas?\n",
    "\n",
    "pandas is one of the most popular open source data exploration libraries currently available. It gives its users the power to explore, query, transform, aggregate, and visualize **tabular** data. Tabular refers to data that is two-dimensional, consisting of rows and columns. Commonly, we refer to this organized structure of data as a **table**. pandas is the tool that we will use to analyze data in nearly every chapter of this book.\n",
    "\n",
    "## pandas is built directly on numpy\n",
    "\n",
    "numpy('numerical Python') is the most popular third-party Python library for scientific computing and forms the foundation for dozens of others, including pandas. numpy's primary data structure is an n-dimensional array which is much more powerful than a Python list and with much better performance for numerical operations.\n",
    "\n",
    "All of the data in pandas is stored in numpy arrays. That said, it isn't necessary to know much about numpy when learning pandas. You can think of pandas as a higher-level, easier to use interface for doing data analysis than numpy. It is a good idea to eventually learn numpy, but for most data analysis tasks, pandas will be the right tool.\n",
    "\n",
    "## pandas operates on tabular data\n",
    "\n",
    "There are numerous formats for data, such as XML, JSON, CSV, Parquet, raw bytes, and many others. pandas has the capability to read in many different formats of data and always converts it to tabular form. pandas is built just for analyzing this rectangular, deceptively normal concept of data. pandas is not a suitable library for handling data in more than two-dimensions. It's focus is strictly on data that is one or two dimensions.\n",
    "\n",
    "### The DataFrame and Series\n",
    "\n",
    "The DataFrame and Series are the two primary pandas objects that we use throughout this book.\n",
    "* **DataFrame** - A two-dimensional data structure that looks like any other rectangular table of data with rows and columns.\n",
    "* **Series** - A single dimension of data. It is analogous to a single column of data or a one-dimensional array.\n",
    "\n",
    "## pandas examples\n",
    "\n",
    "The rest of this chapter contains examples of common data analysis tasks with pandas. There are one or two examples from each of the following major areas of the library:\n",
    "* Reading data, \n",
    "* Filtering data\n",
    "* Aggregating methods\n",
    "* Non-Aggregating methods\n",
    "* Aggregating within groups\n",
    "* Cleaning data\n",
    "* Joining data\n",
    "* Time series analysis\n",
    "* Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "Multiple datasets are used during the rest of this chapter. The `read_csv` function is able to read in data stored in plain text that is separated by a delimiter. By default, the delimiter is a comma. Below, we read in public bike usage data from the city of Chicago into a pandas DataFrame named `bikes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>6/28/2013 19:01</td>\n",
       "      <td>6/28/2013 19:17</td>\n",
       "      <td>993</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11</td>\n",
       "      <td>Michigan Ave &amp; Oak St</td>\n",
       "      <td>15</td>\n",
       "      <td>73.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>6/28/2013 22:53</td>\n",
       "      <td>6/28/2013 23:03</td>\n",
       "      <td>623</td>\n",
       "      <td>Clinton St &amp; Washington Blvd</td>\n",
       "      <td>31</td>\n",
       "      <td>Wells St &amp; Walton St</td>\n",
       "      <td>19</td>\n",
       "      <td>69.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>6/30/2013 14:43</td>\n",
       "      <td>6/30/2013 15:01</td>\n",
       "      <td>1040</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15</td>\n",
       "      <td>Dearborn St &amp; Monroe St</td>\n",
       "      <td>23</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender        starttime         stoptime  tripduration  \\\n",
       "0   Male  6/28/2013 19:01  6/28/2013 19:17           993   \n",
       "1   Male  6/28/2013 22:53  6/28/2013 23:03           623   \n",
       "2   Male  6/30/2013 14:43  6/30/2013 15:01          1040   \n",
       "\n",
       "              from_station_name  start_capacity          to_station_name  \\\n",
       "0     Lake Shore Dr & Monroe St              11    Michigan Ave & Oak St   \n",
       "1  Clinton St & Washington Blvd              31     Wells St & Walton St   \n",
       "2  Sheffield Ave & Kingsbury St              15  Dearborn St & Monroe St   \n",
       "\n",
       "   end_capacity  temperature  wind_speed        events  \n",
       "0            15         73.9        12.7  mostlycloudy  \n",
       "1            19         69.1         6.9  partlycloudy  \n",
       "2            23         73.0        16.1  mostlycloudy  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bikes = pd.read_csv('input/bikes.csv')\n",
    "bikes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data\n",
    "\n",
    "pandas can filter the rows of a DataFrame based on whether the values in that row meet a condition. For instance, we can select only the rides that had a `tripduration` greater than 5,000 (seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Condition\n",
    "\n",
    "This example is a single condition that gets tested for each row. Only the rows that meet this condition are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Male</td>\n",
       "      <td>7/9/2013 13:12</td>\n",
       "      <td>7/9/2013 14:42</td>\n",
       "      <td>5396</td>\n",
       "      <td>Canal St &amp; Jackson Blvd</td>\n",
       "      <td>35</td>\n",
       "      <td>Millennium Park</td>\n",
       "      <td>35</td>\n",
       "      <td>79.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/14/2013 14:08</td>\n",
       "      <td>7/14/2013 15:53</td>\n",
       "      <td>6274</td>\n",
       "      <td>Wabash Ave &amp; Roosevelt Rd</td>\n",
       "      <td>19</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11</td>\n",
       "      <td>87.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/21/2013 11:35</td>\n",
       "      <td>7/21/2013 13:54</td>\n",
       "      <td>8299</td>\n",
       "      <td>State St &amp; 19th St</td>\n",
       "      <td>15</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15</td>\n",
       "      <td>82.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender        starttime         stoptime  tripduration  \\\n",
       "18    Male   7/9/2013 13:12   7/9/2013 14:42          5396   \n",
       "40  Female  7/14/2013 14:08  7/14/2013 15:53          6274   \n",
       "77  Female  7/21/2013 11:35  7/21/2013 13:54          8299   \n",
       "\n",
       "            from_station_name  start_capacity               to_station_name  \\\n",
       "18    Canal St & Jackson Blvd              35               Millennium Park   \n",
       "40  Wabash Ave & Roosevelt Rd              19     Lake Shore Dr & Monroe St   \n",
       "77         State St & 19th St              15  Sheffield Ave & Kingsbury St   \n",
       "\n",
       "    end_capacity  temperature  wind_speed        events  \n",
       "18            35         79.0        13.8        cloudy  \n",
       "40            11         87.1         8.1  partlycloudy  \n",
       "77            15         82.9         5.8  mostlycloudy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = bikes['tripduration'] > 5000\n",
    "bikes[filt].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Conditions\n",
    "\n",
    "We can test for multiple conditions in a single row. The following example returns rides by females **and** have a `tripduration` greater than 5,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/14/2013 14:08</td>\n",
       "      <td>7/14/2013 15:53</td>\n",
       "      <td>6274</td>\n",
       "      <td>Wabash Ave &amp; Roosevelt Rd</td>\n",
       "      <td>19</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11</td>\n",
       "      <td>87.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/21/2013 11:35</td>\n",
       "      <td>7/21/2013 13:54</td>\n",
       "      <td>8299</td>\n",
       "      <td>State St &amp; 19th St</td>\n",
       "      <td>15</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15</td>\n",
       "      <td>82.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>Female</td>\n",
       "      <td>12/28/2013 11:37</td>\n",
       "      <td>12/28/2013 13:34</td>\n",
       "      <td>7050</td>\n",
       "      <td>LaSalle St &amp; Washington St</td>\n",
       "      <td>15</td>\n",
       "      <td>Theater on the Lake</td>\n",
       "      <td>15</td>\n",
       "      <td>44.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender         starttime          stoptime  tripduration  \\\n",
       "40    Female   7/14/2013 14:08   7/14/2013 15:53          6274   \n",
       "77    Female   7/21/2013 11:35   7/21/2013 13:54          8299   \n",
       "1954  Female  12/28/2013 11:37  12/28/2013 13:34          7050   \n",
       "\n",
       "               from_station_name  start_capacity  \\\n",
       "40     Wabash Ave & Roosevelt Rd              19   \n",
       "77            State St & 19th St              15   \n",
       "1954  LaSalle St & Washington St              15   \n",
       "\n",
       "                   to_station_name  end_capacity  temperature  wind_speed  \\\n",
       "40       Lake Shore Dr & Monroe St            11         87.1         8.1   \n",
       "77    Sheffield Ave & Kingsbury St            15         82.9         5.8   \n",
       "1954           Theater on the Lake            15         44.1        12.7   \n",
       "\n",
       "            events  \n",
       "40    partlycloudy  \n",
       "77    mostlycloudy  \n",
       "1954         clear  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt1 = bikes['tripduration'] > 5000\n",
    "filt2 = bikes['gender'] == 'Female'\n",
    "filt = filt1 & filt2\n",
    "bikes[filt].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example has multiple conditions but only requires that one of the conditions is true. It returns all the rows where either the rider is female **or** the `tripduration` is greater than 5,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/4/2013 15:00</td>\n",
       "      <td>7/4/2013 15:16</td>\n",
       "      <td>922</td>\n",
       "      <td>Lakeview Ave &amp; Fullerton Pkwy</td>\n",
       "      <td>19</td>\n",
       "      <td>Racine Ave &amp; Congress Pkwy</td>\n",
       "      <td>19</td>\n",
       "      <td>81.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/6/2013 12:39</td>\n",
       "      <td>7/6/2013 12:49</td>\n",
       "      <td>610</td>\n",
       "      <td>Morgan St &amp; Lake St</td>\n",
       "      <td>15</td>\n",
       "      <td>Aberdeen St &amp; Jackson Blvd</td>\n",
       "      <td>15</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Male</td>\n",
       "      <td>7/9/2013 13:12</td>\n",
       "      <td>7/9/2013 14:42</td>\n",
       "      <td>5396</td>\n",
       "      <td>Canal St &amp; Jackson Blvd</td>\n",
       "      <td>35</td>\n",
       "      <td>Millennium Park</td>\n",
       "      <td>35</td>\n",
       "      <td>79.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender       starttime        stoptime  tripduration  \\\n",
       "9   Female  7/4/2013 15:00  7/4/2013 15:16           922   \n",
       "14  Female  7/6/2013 12:39  7/6/2013 12:49           610   \n",
       "18    Male  7/9/2013 13:12  7/9/2013 14:42          5396   \n",
       "\n",
       "                from_station_name  start_capacity             to_station_name  \\\n",
       "9   Lakeview Ave & Fullerton Pkwy              19  Racine Ave & Congress Pkwy   \n",
       "14            Morgan St & Lake St              15  Aberdeen St & Jackson Blvd   \n",
       "18        Canal St & Jackson Blvd              35             Millennium Park   \n",
       "\n",
       "    end_capacity  temperature  wind_speed        events  \n",
       "9             19         81.0        12.7  mostlycloudy  \n",
       "14            15         82.0         5.8  mostlycloudy  \n",
       "18            35         79.0        13.8        cloudy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = filt1 | filt2\n",
    "bikes[filt].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `query` method\n",
    "\n",
    "The `query` method provides an alternative and often more readable way to filter data than the above. All three filtering examples from above may be duplicated with `query`. A string representing the condition is passed to the `query` method to filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Male</td>\n",
       "      <td>7/9/2013 13:12</td>\n",
       "      <td>7/9/2013 14:42</td>\n",
       "      <td>5396</td>\n",
       "      <td>Canal St &amp; Jackson Blvd</td>\n",
       "      <td>35</td>\n",
       "      <td>Millennium Park</td>\n",
       "      <td>35</td>\n",
       "      <td>79.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/14/2013 14:08</td>\n",
       "      <td>7/14/2013 15:53</td>\n",
       "      <td>6274</td>\n",
       "      <td>Wabash Ave &amp; Roosevelt Rd</td>\n",
       "      <td>19</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11</td>\n",
       "      <td>87.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/21/2013 11:35</td>\n",
       "      <td>7/21/2013 13:54</td>\n",
       "      <td>8299</td>\n",
       "      <td>State St &amp; 19th St</td>\n",
       "      <td>15</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15</td>\n",
       "      <td>82.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender        starttime         stoptime  tripduration  \\\n",
       "18    Male   7/9/2013 13:12   7/9/2013 14:42          5396   \n",
       "40  Female  7/14/2013 14:08  7/14/2013 15:53          6274   \n",
       "77  Female  7/21/2013 11:35  7/21/2013 13:54          8299   \n",
       "\n",
       "            from_station_name  start_capacity               to_station_name  \\\n",
       "18    Canal St & Jackson Blvd              35               Millennium Park   \n",
       "40  Wabash Ave & Roosevelt Rd              19     Lake Shore Dr & Monroe St   \n",
       "77         State St & 19th St              15  Sheffield Ave & Kingsbury St   \n",
       "\n",
       "    end_capacity  temperature  wind_speed        events  \n",
       "18            35         79.0        13.8        cloudy  \n",
       "40            11         87.1         8.1  partlycloudy  \n",
       "77            15         82.9         5.8  mostlycloudy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.query('tripduration > 5000').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/14/2013 14:08</td>\n",
       "      <td>7/14/2013 15:53</td>\n",
       "      <td>6274</td>\n",
       "      <td>Wabash Ave &amp; Roosevelt Rd</td>\n",
       "      <td>19</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11</td>\n",
       "      <td>87.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/21/2013 11:35</td>\n",
       "      <td>7/21/2013 13:54</td>\n",
       "      <td>8299</td>\n",
       "      <td>State St &amp; 19th St</td>\n",
       "      <td>15</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15</td>\n",
       "      <td>82.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>Female</td>\n",
       "      <td>12/28/2013 11:37</td>\n",
       "      <td>12/28/2013 13:34</td>\n",
       "      <td>7050</td>\n",
       "      <td>LaSalle St &amp; Washington St</td>\n",
       "      <td>15</td>\n",
       "      <td>Theater on the Lake</td>\n",
       "      <td>15</td>\n",
       "      <td>44.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender         starttime          stoptime  tripduration  \\\n",
       "40    Female   7/14/2013 14:08   7/14/2013 15:53          6274   \n",
       "77    Female   7/21/2013 11:35   7/21/2013 13:54          8299   \n",
       "1954  Female  12/28/2013 11:37  12/28/2013 13:34          7050   \n",
       "\n",
       "               from_station_name  start_capacity  \\\n",
       "40     Wabash Ave & Roosevelt Rd              19   \n",
       "77            State St & 19th St              15   \n",
       "1954  LaSalle St & Washington St              15   \n",
       "\n",
       "                   to_station_name  end_capacity  temperature  wind_speed  \\\n",
       "40       Lake Shore Dr & Monroe St            11         87.1         8.1   \n",
       "77    Sheffield Ave & Kingsbury St            15         82.9         5.8   \n",
       "1954           Theater on the Lake            15         44.1        12.7   \n",
       "\n",
       "            events  \n",
       "40    partlycloudy  \n",
       "77    mostlycloudy  \n",
       "1954         clear  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.query('tripduration > 5000 and gender==\"Female\"').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/4/2013 15:00</td>\n",
       "      <td>7/4/2013 15:16</td>\n",
       "      <td>922</td>\n",
       "      <td>Lakeview Ave &amp; Fullerton Pkwy</td>\n",
       "      <td>19</td>\n",
       "      <td>Racine Ave &amp; Congress Pkwy</td>\n",
       "      <td>19</td>\n",
       "      <td>81.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Female</td>\n",
       "      <td>7/6/2013 12:39</td>\n",
       "      <td>7/6/2013 12:49</td>\n",
       "      <td>610</td>\n",
       "      <td>Morgan St &amp; Lake St</td>\n",
       "      <td>15</td>\n",
       "      <td>Aberdeen St &amp; Jackson Blvd</td>\n",
       "      <td>15</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Male</td>\n",
       "      <td>7/9/2013 13:12</td>\n",
       "      <td>7/9/2013 14:42</td>\n",
       "      <td>5396</td>\n",
       "      <td>Canal St &amp; Jackson Blvd</td>\n",
       "      <td>35</td>\n",
       "      <td>Millennium Park</td>\n",
       "      <td>35</td>\n",
       "      <td>79.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender       starttime        stoptime  tripduration  \\\n",
       "9   Female  7/4/2013 15:00  7/4/2013 15:16           922   \n",
       "14  Female  7/6/2013 12:39  7/6/2013 12:49           610   \n",
       "18    Male  7/9/2013 13:12  7/9/2013 14:42          5396   \n",
       "\n",
       "                from_station_name  start_capacity             to_station_name  \\\n",
       "9   Lakeview Ave & Fullerton Pkwy              19  Racine Ave & Congress Pkwy   \n",
       "14            Morgan St & Lake St              15  Aberdeen St & Jackson Blvd   \n",
       "18        Canal St & Jackson Blvd              35             Millennium Park   \n",
       "\n",
       "    end_capacity  temperature  wind_speed        events  \n",
       "9             19         81.0        12.7  mostlycloudy  \n",
       "14            15         82.0         5.8  mostlycloudy  \n",
       "18            35         79.0        13.8        cloudy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.query('tripduration > 5000 or gender==\"Female\"').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating methods\n",
    "\n",
    "The technical definition of an **aggregation** is when a sequence of values is summarized by a **single** number. For example, `sum`, `mean`, `median`, `max`, and `min` are all examples of aggregation methods. By default, calling these methods on a pandas DataFrame applies the aggregation to each column. Below, we use a dataset containing San Francisco employee compensation information. Only a subset of the columns are initially read into the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salaries</th>\n",
       "      <th>overtime</th>\n",
       "      <th>other salaries</th>\n",
       "      <th>retirement</th>\n",
       "      <th>health and dental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71414.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14038.58</td>\n",
       "      <td>12918.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67941.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13030.23</td>\n",
       "      <td>10047.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116956.72</td>\n",
       "      <td>59975.43</td>\n",
       "      <td>19037.3</td>\n",
       "      <td>24796.44</td>\n",
       "      <td>15788.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salaries  overtime  other salaries  retirement  health and dental\n",
       "0   71414.01      0.00             0.0    14038.58           12918.24\n",
       "1   67941.06      0.00             0.0    13030.23           10047.52\n",
       "2  116956.72  59975.43         19037.3    24796.44           15788.97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['salaries', 'overtime', 'other salaries', 'retirement', 'health and dental']\n",
    "sf_emp = pd.read_csv('input/sf_employee_compensation.csv', usecols=cols)\n",
    "sf_emp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `mean` method returns the mean of each column. The result is then rounded to the nearest thousand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salaries             63689.182149\n",
       "overtime              4369.738196\n",
       "other salaries        3909.401825\n",
       "retirement           12131.039922\n",
       "health and dental     9154.667163\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_emp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas allows you to aggregate rows as well. The `axis` parameter may be used to change the direction of the aggregation. This returns the total compensation for each employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     98370.83\n",
       "1     91018.81\n",
       "2    236554.86\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_emp.sum(axis=1).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-aggregating methods\n",
    "\n",
    "There are methods that perform some calculation on the DataFrame that do not aggregate the data and usually preserve the shape of the DataFrame. For example, the `round` method rounds each number to a given decimal place. Here, we round each value in the DataFrame to the nearest thousand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salaries</th>\n",
       "      <th>overtime</th>\n",
       "      <th>other salaries</th>\n",
       "      <th>retirement</th>\n",
       "      <th>health and dental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>13000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salaries  overtime  other salaries  retirement  health and dental\n",
       "0   71000.0       0.0             0.0     14000.0            13000.0\n",
       "1   68000.0       0.0             0.0     13000.0            10000.0\n",
       "2  117000.0   60000.0         19000.0     25000.0            16000.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_emp.round(-3).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating within groups\n",
    "\n",
    "Above, we performed aggregations on the entire DataFrame. We can instead perform aggregations within groups of the data. Below we use an insurance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/insurance.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CTI110~1\\AppData\\Local\\Temp/ipykernel_4944/543548384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input/insurance.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/insurance.csv'"
     ]
    }
   ],
   "source": [
    "ins = pd.read_csv('input/insurance.csv')\n",
    "ins.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest aggregations is the frequency of occurrence of all the unique values within a single column. This is performed below with the `value_counts` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of unique values in a single column\n",
    "\n",
    "Here, we count the occurrence of each individual `region`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single aggregation function\n",
    "\n",
    "Let's say we wish to find the mean charges for each of the unique values in the `sex` column. The `groupby` method creates groups based on the given grouping column before applying the aggregation. In this example, we return the mean charges for each sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.groupby('sex').agg(mean_charges=('charges', 'mean')).round(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple aggregation functions\n",
    "\n",
    "pandas allows us to perform multiple aggregations at the same time. Below, we calculate the mean and max of the `charges` column as well as count the number of non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.groupby('sex').agg(mean_charges=('charges', 'mean'),\n",
    "                       max_charges=('charges', 'max'),\n",
    "                       count_charges=('charges', 'count')).round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple grouping columns\n",
    "\n",
    "pandas allows us to form groups based on multiple columns. In the below example, each unique combination of `sex` and `region` form a group. For each of these groups, the same aggregations as above are performed on the `charges` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.groupby(['sex', 'region']).agg(mean_charges=('charges', 'mean'),\n",
    "                                   max_charges=('charges', 'max'),\n",
    "                                   count_charges=('charges', 'count')).round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tables\n",
    "\n",
    "We can reproduce the exact same output as above in a different shape with the `pivot_table` method. It groups and aggregates the same way as `groupby`, but places the unique values of one of the grouping columns as the new columns in the resulting DataFrame. Notice that pivot tables make for easier comparisons across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = ins.pivot_table(index='sex', columns='region', \n",
    "                     values='charges', aggfunc='mean').round(0)\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Styling DataFrames\n",
    "\n",
    "pandas enables you to style DataFrames in various ways to provide emphasis on particular cells. Below, the maximum value of each column is highlighted, a comma is added to separate the digits, and decimals are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.style.highlight_max().format(r'{:,.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "\n",
    "Many datasets need to be cleaned before analyzed. pandas provides many tools to prepare data for further analysis.\n",
    "\n",
    "### Options in the `read_csv` function\n",
    "\n",
    "Below, we read in a new dataset on plane crashes. Notice all the question marks. They represent missing values, but pandas will read them in as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pd.read_csv('input/planecrashinfo.csv')\n",
    "pc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv` function has dozens of options to help read in messy data. One of the options allows you to convert a particular string to missing values. Notice that all of the question marks are now labeled as `NaN` (not a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pd.read_csv('input/planecrashinfo.csv', na_values='?')\n",
    "pc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String manipulation\n",
    "\n",
    "Often times there is data trapped within a string column that you will need to extract. The `aboard` column appears to have three distinct pieces of information; the total number of people on board, the number of passengers, and the number of crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboard = pc['aboard']\n",
    "aboard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has special functionality for manipulating strings. Below, we use a regular expression to extract the pertinent numbers from the `aboard` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboard.str.extract(r'(\\d+)?\\D*(\\d+)?\\D*(\\d+)?').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping into tidy form\n",
    "\n",
    "Occasionally, you will have several columns of data that all belong in a single column. Take a look at the DataFrame below on the average arrival delay of airlines at different airports. All of the columns with three-letter airport codes could be placed in the same column as they all contain the arrival delay which has the same units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aad = pd.read_csv('input/average_arrival_delay.csv').head()\n",
    "aad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `melt` method stacks columns one on top of the other. Here, it places all of the three-letter airport code columns into a single column. The first two airports (ATL and DEN) are shown below in the new tidy DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aad.melt(id_vars='airline', var_name='airport', value_name='delay').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Data\n",
    "\n",
    "pandas can join multiple DataFrames together by matching values in one or more columns. If you are familiar with SQL, then pandas performs joins in a similar fashion. Below, we make a connection to a database and read in two of its tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine('sqlite:///../data/databases/neurIPS.db')\n",
    "# authors = pd.read_sql('Authors', engine)\n",
    "# pa = pd.read_sql('PaperAuthors', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the first three rows of each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now join these tables together using the `merge` method. The `AuthorID` column from the `pa` table is aligned with the `Id` column of the `authors` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa.merge(authors, how='left', left_on='AuthorId', right_on='Id').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis\n",
    "\n",
    "One of the original purposes of pandas was to do time series analysis. Below, we read in 20 years of Microsoft's closing stock price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = pd.read_csv('input/msft20.csv', parse_dates=['date'], index_col='date')\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a period of time\n",
    "\n",
    "pandas allows us to easily select a period of time. Below, we select all of the trading data from February 27, 2017 through March 2, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft['2017-02-27':'2017-03-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by time\n",
    "\n",
    "We can group by some length of time. Here, we group together every month of trading data and return the average closing price of that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msft_mc = msft.resample('M').agg({'close':'mean'})\n",
    "msft_mc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
