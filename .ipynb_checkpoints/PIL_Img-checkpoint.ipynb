{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\cti110016\\anaconda3\\lib\\site-packages (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image.open() : 開啟指定照片，後面括弧要放路徑\n",
    "- show() : 顯示指定照片，前面要接變數名稱以及點號\n",
    "- save() : 將處理完的照片存檔，前面要接變數名稱以及點號\n",
    "- size() : 取得圖片長寬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "Size:  (242, 255)\n",
      "Width , Height =>  242 , 255\n",
      "Width:  242\n",
      "Height:  255\n",
      "Format:  PNG\n",
      "Color Mode: RGBA\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as MyImage\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "\n",
    "print(\"Type: \",type(img))\n",
    "img_size=img.size\n",
    "print(\"Size: \",img_size)\n",
    "\n",
    "w=img_size[0]\n",
    "h=img_size[1]\n",
    "print(\"Width , Height => \",w,\",\",h)\n",
    "print(\"Width: \",img.width)\n",
    "print(\"Height: \",img.height)\n",
    "print(\"Format: \",img.format)\n",
    "print(\"Color Mode:\",img.mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 照片旋轉 (rotate & Flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "newImg = img.rotate(90) \n",
    "newImg.show()\n",
    "newImg.save(\"./output/Sample90.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "\n",
    "#img_transpose=img.transpose(MyImage.ROTATE_90)\n",
    "#img_transpose=img_transpose.transpose(MyImage.ROTATE_90)\n",
    "#----------flip-----------\n",
    "img_transpose=img.transpose(MyImage.FLIP_TOP_BOTTOM)\n",
    "img_transpose.show()\n",
    "#--------- save image------------\n",
    "img_transpose.save(\"./output/Sample_flip.png\")\n",
    "#img_transpose.save(\"Out/me_2021_rotate90.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "newImg = img\n",
    "newImg.save(\"./output/Sample.png\",\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 灰階轉換 (convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "newImg = img.convert('1')  \n",
    "newImg.show()\n",
    "newImg.save(\"./output/Sample_convert.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更改圖片尺寸 (resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "newImg = img.resize((50,100),Image.LANCZOS)   #img.resize((int(img.width/4),int(img.height/4)))\n",
    "newImg.show()\n",
    "newImg.save(\"./output/Sample_size.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 裁切圖片 (crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "\n",
    "img= MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "    \n",
    "img_cropped=img.crop((180,100,290,145))    #( X,Y , X1,Y1) => ( X,Y , X+width,Y+height )\n",
    "img_cropped.show()\n",
    "img_cropped.save(\"./output/Sample_crop.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌字 (Draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "img  = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "draw = ImageDraw.Draw(img)\n",
    "font  = ImageFont.truetype(\"kaiu.ttf\", 20)\n",
    "color  = \"purple\"\n",
    "text = \"Test\"\n",
    "draw.text((10, 10), text, fill=color, font=font)\n",
    "\n",
    "img.show()\n",
    "img.save(\"./output/Sample_sign.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageDraw as MyImgDraw\n",
    "\n",
    "img =MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "ImgDraw=MyImgDraw.Draw(img)\n",
    "ImgDraw.text((100,100),\"Hi, I am juck30808!\",fill=(200,0,0))    #RGB\n",
    "\n",
    "img.show()\n",
    "img.save(\"./output/Sample_draw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageDraw as MyImgDraw\n",
    "import PIL.ImageFont as MyImgFont\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "\n",
    "#MyFont=MyImgFont.truetype(\"tt1034m_.ttf\",28)\n",
    "MyFont=MyImgFont.truetype(\"input/font1.ttf\",50)\n",
    "ImgDraw=MyImgDraw.Draw(img)\n",
    "ImgDraw.text((10,50),\"juck30808!\",font=MyFont, fill=(200,0,0))#red,green,blue\n",
    "\n",
    "img.show()\n",
    "img.save(\"./output/Sample_draw.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複製 (thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img_copy=img.copy()\n",
    "img_copy.thumbnail((100,100))\n",
    "img_copy.show()\n",
    "\n",
    "img_copy.save(\"./output/Sample_copy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調整濾鏡 (Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "#Blur_Image=img.filter(MyFilter.BLUR)\n",
    "#Blur_Image=img.filter(MyFilter.BoxBlur(1))\n",
    "Blur_Image=img.filter(MyFilter.GaussianBlur(radius=20))\n",
    "\n",
    "Blur_Image.show()\n",
    "Blur_Image.save(\"./output/Sample_FilterBlur.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Sharpen_Image=img.filter(MyFilter.SHARPEN)\n",
    "\n",
    "Sharpen_Image.show()\n",
    "Sharpen_Image.save(\"./output/Sample_FilterSharpen.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img=MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Smooth_Image=img.filter(MyFilter.SMOOTH_MORE)\n",
    "\n",
    "Smooth_Image.show()\n",
    "Smooth_Image.save(\"./output/Sample_FilterSmooth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Contour_Image=img.filter(MyFilter.CONTOUR)\n",
    "\n",
    "Contour_Image.show()\n",
    "Contour_Image.save(\"./output/Sample_FilterCounter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Detail_Image=img.filter(MyFilter.DETAIL)\n",
    "\n",
    "Detail_Image.show()\n",
    "Detail_Image.save(\"./output/Sample_FilterDETAIL.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "EdgeEn_Image=img.filter(MyFilter.EDGE_ENHANCE_MORE)\n",
    "\n",
    "EdgeEn_Image.show()\n",
    "EdgeEn_Image.save(\"./output/Sample_FilterEdge.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Find_Edges_Image=img.filter(MyFilter.FIND_EDGES)\n",
    "\n",
    "Find_Edges_Image.show()\n",
    "Find_Edges_Image.save(\"./output/Sample_FilterFEdge.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Emboss_Image=img.filter(MyFilter.EMBOSS)\n",
    "Emboss_Image.show()\n",
    "\n",
    "Emboss_Image.save(\"./output/Sample_FilterEmboss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "pil_g = Image.open('Garden.jpeg')\n",
    "pil_g.show()  \n",
    "pil_g_b = pil_g.filter(ImageFilter.BLUR()) \n",
    "pil_g_b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "pil_g = Image.open('Garden.jpeg')\n",
    "\n",
    "pil_g.show() \n",
    "draw = ImageDraw.Draw(pil_g)\n",
    "draw.rectangle((100, 200, 850, 950), outline=(255,0,255), width = 10)\n",
    "\n",
    "draw.line((100, 200, 850, 950), fill=(0,0,255), width = 5)\n",
    "\n",
    "pil_g.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "pil_g = Image.open('Garden.jpeg')\n",
    "pil_g.show() \n",
    "draw = ImageDraw.Draw(pil_g)\n",
    "draw.rectangle((100, 200, 550, 650), \n",
    "               outline=(0,0,0), width = 10)\n",
    "draw.line((100, 200, 550, 650), width = 5)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 40)\n",
    "draw.text((250,650), \"This is a beautiful Garden\", \n",
    "          font=fnt, fill=(255,0,255))\n",
    "\n",
    "pil_g.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合併圖片 combine (paste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "imageA = Image.open('./input/Sample.png')\n",
    "imageB = Image.open('./input/dogeweak.png')\n",
    "imageB = imageB.convert(\"RGBA\")\n",
    "widthB , heightB = imageB.size\n",
    "\n",
    "newimageB  = imageB.resize((int(widthB*0.2),int(heightB*0.2)),Image.LANCZOS)\n",
    "\n",
    "resultPicture = Image.new('RGBA', imageA.size, (0, 0, 0, 0))\n",
    "\n",
    "resultPicture.paste(imageA,(0,0))\n",
    "resultPicture.paste(newimageB, (0,0), newimageB)\n",
    "resultPicture.show()\n",
    "resultPicture.save(\"./output/result.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and add Logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "SQUARE_FIT_SIZE = 300\n",
    "LOGO_FILENAME = 'input/catlogo.png'\n",
    "logoIm = Image.open(LOGO_FILENAME)\n",
    "logoWidth, logoHeight = logoIm.size\n",
    "os.makedirs('withLogo', exist_ok=True)\n",
    "\n",
    "# Loop over all files in the working directory.\n",
    "for filename in os.listdir('.'):\n",
    "    if not (filename.lower().endswith('.png') or filename.lower().endswith('.jpg')\n",
    "            or filename.lower().endswith('.gif') or filename.lower().endswith('bmp')) \\\n",
    "        or filename == LOGO_FILENAME:\n",
    "        continue # skip non-image files and the logo file itself\n",
    "\n",
    "    im = Image.open(filename)\n",
    "    width, height = im.size\n",
    "\n",
    "    # Check if image needs to be resized.\n",
    "    if width > SQUARE_FIT_SIZE and height > SQUARE_FIT_SIZE:\n",
    "        # Calculate the new width and height to resize to.\n",
    "        if width > height:\n",
    "            height = int((SQUARE_FIT_SIZE / width) * height)\n",
    "            width = SQUARE_FIT_SIZE\n",
    "        else:\n",
    "            width = int((SQUARE_FIT_SIZE / height) * width)\n",
    "            height = SQUARE_FIT_SIZE\n",
    "\n",
    "    # Resize the image.\n",
    "    print('Resizing %s...' % (filename))\n",
    "    im = im.resize((width, height))\n",
    "\n",
    "    # Add the logo if it fits properly in image.\n",
    "    imWidth, imHeight = im.size\n",
    "    if imWidth < logoWidth * 2 and imHeight < logoHeight * 2:\n",
    "        print(\"Logo taking up too much space in image so skipped..\")\n",
    "    else:\n",
    "        print('Adding logo to %s...' % (filename))\n",
    "        im.paste(logoIm, (width - logoWidth, height - logoHeight), logoIm)\n",
    "\n",
    "    # Save changes.\n",
    "    im.save(os.path.join('withLogo', filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Employee No'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Employee No'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9q/486czkcn7lv5v0hwbt71twdc0000gn/T/ipykernel_1749/150506328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Module 1 Reference Data Load Module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input/Employee.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mempno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Employee No\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mfirstname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"First Name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlastname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Last Name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Employee No'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('input/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dr. Xavier Chelladurai\n",
    "#06 April 2020\n",
    "#Program to load a color picture and find shape\n",
    "import face_recognition\n",
    "photo_xavi = face_recognition.load_image_file('./xavier/xavier01.png','L')\n",
    "photo_alwy = face_recognition.load_image_file('./alwyn/alwyn01.jpeg','L')\n",
    "photo_arun = face_recognition.load_image_file('./arun/arun01.jpeg','L')\n",
    "print(\"The shapes of the bw photo files are...\")\n",
    "print(\"Xavier Photo....\",photo_xavi.shape)\n",
    "print(\"Alwyn Photo.....\", photo_alwy.shape)\n",
    "print(\"Arun Photo......\", photo_arun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "photo_xavi = face_recognition.load_image_file('./xavier/xavier01.png','RGB')\n",
    "photo_alwy = face_recognition.load_image_file('./alwyn/alwyn01.jpeg','RGB')\n",
    "photo_arun = face_recognition.load_image_file('./arun/arun01.jpeg')\n",
    "print(\"The shapes of the Color photo files are...\")\n",
    "print(\"Xavier Photo....\",photo_xavi.shape)\n",
    "print(\"Alwyn Photo.....\", photo_alwy.shape)\n",
    "print(\"Arun Photo......\", photo_arun.shape)\n",
    "pil_image_xavi = Image.fromarray(photo_xavi)\n",
    "pil_image_xavi.show()\n",
    "pil_image_alwy = Image.fromarray(photo_alwy)\n",
    "pil_image_alwy.show()\n",
    "pil_image_arun = Image.fromarray(photo_arun)\n",
    "pil_image_arun.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)\n",
    "    \n",
    "# Module 5 Display Attendance Module\n",
    "pil_uk = Image.fromarray(uk)\n",
    "draw = ImageDraw.Draw(pil_uk)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 60)\n",
    "\n",
    "if emp_index ==-1:\n",
    "    name =\"Face NOT Recognized\"\n",
    "else:\n",
    "    name = firstname[emp_index]+\" \"+lastname[emp_index]\n",
    "x = 100\n",
    "y = uk.shape[0] - 100\n",
    "draw.text((x, y), name, font=fnt, fill=(250,0,0))\n",
    "pil_uk.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "xavi_photo = face_recognition.load_image_file('./xavier/xavier01.png')\n",
    "print(xavi_photo.shape)\n",
    "l = face_recognition.face_locations(xavi_photo, model = 'hog')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "xavi_face = xavi_photo[top:bottom, left:right]\n",
    "print(xavi_face.shape)\n",
    "xavi_face_image = Image.fromarray(xavi_face)\n",
    "xavi_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)\n",
    "    \n",
    "# Module 5 Display Attendance Module\n",
    "pil_uk = Image.fromarray(uk)\n",
    "draw = ImageDraw.Draw(pil_uk)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 60)\n",
    "\n",
    "if emp_index ==-1:\n",
    "    name =\"Face NOT Recognized\"\n",
    "else:\n",
    "    name = firstname[emp_index]+\" \"+lastname[emp_index]\n",
    "x = 100\n",
    "y = uk.shape[0] - 100\n",
    "draw.text((x, y), name, font=fnt, fill=(0,0,0))\n",
    "pil_uk.show()\n",
    "\n",
    "# Module 6 Announce Attendance Recorded Module\n",
    "audioloc = audiolocation[emp_index]\n",
    "pygame.mixer.init()\n",
    "if emp_index ==-1:\n",
    "    pygame.mixer.music.load(\n",
    "        \"./DataFiles/EmployeeAudio/failure.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "else:\n",
    "    pygame.mixer.music.load(audioloc)\n",
    "    pygame.mixer.music.play()\n",
    "    pygame.mixer.music.queue(\n",
    "        \"./DataFiles/EmployeeAudio/success.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)\n",
    "    \n",
    "# Module 5 Display Attendance Module\n",
    "pil_uk = Image.fromarray(uk)\n",
    "draw = ImageDraw.Draw(pil_uk)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 60)\n",
    "\n",
    "if emp_index ==-1:\n",
    "    name =\"Face NOT Recognized\"\n",
    "else:\n",
    "    name = firstname[emp_index]+\" \"+lastname[emp_index]\n",
    "x = 100\n",
    "y = uk.shape[0] - 100\n",
    "draw.text((x, y), name, font=fnt, fill=(0,0,0))\n",
    "pil_uk.show()\n",
    "\n",
    "# Module 6 Announce Attendance Recorded Module\n",
    "audioloc = audiolocation[emp_index]\n",
    "pygame.mixer.init()\n",
    "if emp_index ==-1:\n",
    "    pygame.mixer.music.load(\n",
    "        \"./DataFiles/EmployeeAudio/failure.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "else:\n",
    "    pygame.mixer.music.load(audioloc)\n",
    "    pygame.mixer.music.play()\n",
    "    pygame.mixer.music.queue(\n",
    "        \"./DataFiles/EmployeeAudio/success.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "family_photo = face_recognition.load_image_file(\"./group/gr010.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(family_photo, model=\"hog\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = family_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "xavi_photo = face_recognition.load_image_file('./xavier/xavier01.png')\n",
    "print(xavi_photo.shape)\n",
    "l = face_recognition.face_locations(xavi_photo, model ='cnn')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "xavi_image = xavi_photo[top:bottom, left:right]\n",
    "print(xavi_image.shape)\n",
    "xavi_face_image = Image.fromarray(xavi_image)\n",
    "xavi_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "xavi_photo = face_recognition.load_image_file('./xavier/xavier01.png')\n",
    "print(xavi_photo.shape)\n",
    "l = face_recognition.face_locations(xavi_photo)\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "xavi_face = xavi_photo[top:bottom, left:right]\n",
    "print(xavi_face.shape)\n",
    "xavi_face_image = Image.fromarray(xavi_face)\n",
    "#xavi_face_image.show()\n",
    "xavi_photo_image = Image.fromarray(xavi_photo)\n",
    "draw = ImageDraw.Draw(xavi_photo_image)\n",
    "draw.rectangle(\n",
    "   (left, top, right, bottom),\n",
    "   outline = (0, 0, 255), width = 5)\n",
    "xavi_photo_image.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
