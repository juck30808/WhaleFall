{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image.open() : 開啟指定照片，後面括弧要放路徑\n",
    "- show() : 顯示指定照片，前面要接變數名稱以及點號\n",
    "- save() : 將處理完的照片存檔，前面要接變數名稱以及點號\n",
    "- size() : 取得圖片長寬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "Size:  (242, 255)\n",
      "Width , Height =>  242 , 255\n",
      "Width:  242\n",
      "Height:  255\n",
      "Format:  PNG\n",
      "Color Mode: RGBA\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as MyImage\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "\n",
    "print(\"Type: \",type(img))\n",
    "img_size=img.size\n",
    "print(\"Size: \",img_size)\n",
    "\n",
    "w=img_size[0]\n",
    "h=img_size[1]\n",
    "print(\"Width , Height => \",w,\",\",h)\n",
    "print(\"Width: \",img.width)\n",
    "print(\"Height: \",img.height)\n",
    "print(\"Format: \",img.format)\n",
    "print(\"Color Mode:\",img.mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 照片旋轉 (rotate & Flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "newImg = img.rotate(90) \n",
    "newImg.show()\n",
    "newImg.save(\"./output/Sample90.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "\n",
    "#img_transpose=img.transpose(MyImage.ROTATE_90)\n",
    "#img_transpose=img_transpose.transpose(MyImage.ROTATE_90)\n",
    "#----------flip-----------\n",
    "img_transpose=img.transpose(MyImage.FLIP_TOP_BOTTOM)\n",
    "img_transpose.show()\n",
    "#--------- save image------------\n",
    "img_transpose.save(\"./output/Sample_flip.png\")\n",
    "#img_transpose.save(\"Out/me_2021_rotate90.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "newImg = img\n",
    "newImg.save(\"./output/Sample.png\",\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 灰階轉換 (convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "newImg = img.convert('1')  \n",
    "newImg.show()\n",
    "newImg.save(\"./output/Sample_convert.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更改圖片尺寸 (resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "newImg = img.resize((50,100),Image.LANCZOS)   #img.resize((int(img.width/4),int(img.height/4)))\n",
    "newImg.show()\n",
    "newImg.save(\"./output/Sample_size.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 裁切圖片 (crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "\n",
    "img= MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "    \n",
    "img_cropped=img.crop((180,100,290,145))    #( X,Y , X1,Y1) => ( X,Y , X+width,Y+height )\n",
    "img_cropped.show()\n",
    "img_cropped.save(\"./output/Sample_crop.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌字 (Draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9q/486czkcn7lv5v0hwbt71twdc0000gn/T/ipykernel_2623/87676729.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfont\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kaiu.ttf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcolor\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"purple\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mfreetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    209\u001b[0m                         \u001b[0mload_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             self.font = core.getfont(\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             )\n",
      "\u001b[0;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "img  = Image.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "draw = ImageDraw.Draw(img)\n",
    "font  = ImageFont.truetype(\"kaiu.ttf\", 20)\n",
    "color  = \"purple\"\n",
    "text = \"Test\"\n",
    "draw.text((10, 10), text, fill=color, font=font)\n",
    "\n",
    "img.show()\n",
    "img.save(\"./output/Sample_sign.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageDraw as MyImgDraw\n",
    "\n",
    "img =MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "ImgDraw=MyImgDraw.Draw(img)\n",
    "ImgDraw.text((100,100),\"Hi, I am juck30808!\",fill=(200,0,0))    #RGB\n",
    "\n",
    "img.show()\n",
    "img.save(\"./output/Sample_draw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageDraw as MyImgDraw\n",
    "import PIL.ImageFont as MyImgFont\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "\n",
    "#MyFont=MyImgFont.truetype(\"tt1034m_.ttf\",28)\n",
    "MyFont=MyImgFont.truetype(\"input/font1.ttf\",50)\n",
    "ImgDraw=MyImgDraw.Draw(img)\n",
    "ImgDraw.text((10,50),\"juck30808!\",font=MyFont, fill=(200,0,0))#red,green,blue\n",
    "\n",
    "img.show()\n",
    "img.save(\"./output/Sample_draw.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複製 (thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img_copy=img.copy()\n",
    "img_copy.thumbnail((100,100))\n",
    "img_copy.show()\n",
    "\n",
    "img_copy.save(\"./output/Sample_copy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調整濾鏡 (Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "#Blur_Image=img.filter(MyFilter.BLUR)\n",
    "#Blur_Image=img.filter(MyFilter.BoxBlur(1))\n",
    "Blur_Image=img.filter(MyFilter.GaussianBlur(radius=20))\n",
    "\n",
    "Blur_Image.show()\n",
    "Blur_Image.save(\"./output/Sample_FilterBlur.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter transformations\n",
    "from PIL import ImageFilter\n",
    "# Built-in filters:\n",
    "# - ImageFilter.BLUR\n",
    "# - ImageFilter.CONTOUR\n",
    "# - ImageFilter.DETAIL\n",
    "# - ImageFilter.EDGE_ENHANCE\n",
    "# - ImageFilter.EMBOSS\n",
    "# - ImageFilter.FIND_EDGES\n",
    "# - ImageFilter.SHARPEN\n",
    "# - ImageFilter.SMOOTH\n",
    "# - ...and more!\n",
    "out = img.filter(MyFilter.BLUR)\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Sharpen_Image=img.filter(MyFilter.SHARPEN)\n",
    "\n",
    "Sharpen_Image.show()\n",
    "Sharpen_Image.save(\"./output/Sample_FilterSharpen.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img=MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Smooth_Image=img.filter(MyFilter.SMOOTH_MORE)\n",
    "\n",
    "Smooth_Image.show()\n",
    "Smooth_Image.save(\"./output/Sample_FilterSmooth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Contour_Image=img.filter(MyFilter.CONTOUR)\n",
    "\n",
    "Contour_Image.show()\n",
    "Contour_Image.save(\"./output/Sample_FilterCounter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Detail_Image=img.filter(MyFilter.DETAIL)\n",
    "\n",
    "Detail_Image.show()\n",
    "Detail_Image.save(\"./output/Sample_FilterDETAIL.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "EdgeEn_Image=img.filter(MyFilter.EDGE_ENHANCE_MORE)\n",
    "\n",
    "EdgeEn_Image.show()\n",
    "EdgeEn_Image.save(\"./output/Sample_FilterEdge.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Find_Edges_Image=img.filter(MyFilter.FIND_EDGES)\n",
    "\n",
    "Find_Edges_Image.show()\n",
    "Find_Edges_Image.save(\"./output/Sample_FilterFEdge.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as MyImage\n",
    "import PIL.ImageFilter as MyFilter\n",
    "\n",
    "img = MyImage.open(\"./input/Sample.png\")\n",
    "img.show()\n",
    "\n",
    "Emboss_Image=img.filter(MyFilter.EMBOSS)\n",
    "Emboss_Image.show()\n",
    "\n",
    "Emboss_Image.save(\"./output/Sample_FilterEmboss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "pil_g = Image.open('Garden.jpeg')\n",
    "pil_g.show()  \n",
    "pil_g_b = pil_g.filter(ImageFilter.BLUR()) \n",
    "pil_g_b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "pil_g = Image.open('Garden.jpeg')\n",
    "\n",
    "pil_g.show() \n",
    "draw = ImageDraw.Draw(pil_g)\n",
    "draw.rectangle((100, 200, 850, 950), outline=(255,0,255), width = 10)\n",
    "\n",
    "draw.line((100, 200, 850, 950), fill=(0,0,255), width = 5)\n",
    "\n",
    "pil_g.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "pil_g = Image.open('Garden.jpeg')\n",
    "pil_g.show() \n",
    "draw = ImageDraw.Draw(pil_g)\n",
    "draw.rectangle((100, 200, 550, 650), \n",
    "               outline=(0,0,0), width = 10)\n",
    "draw.line((100, 200, 550, 650), width = 5)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 40)\n",
    "draw.text((250,650), \"This is a beautiful Garden\", \n",
    "          font=fnt, fill=(255,0,255))\n",
    "\n",
    "pil_g.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合併圖片 combine (paste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "imageA = Image.open('./input/Sample.png')\n",
    "imageB = Image.open('./input/dogeweak.png')\n",
    "imageB = imageB.convert(\"RGBA\")\n",
    "widthB , heightB = imageB.size\n",
    "\n",
    "newimageB  = imageB.resize((int(widthB*0.2),int(heightB*0.2)),Image.LANCZOS)\n",
    "\n",
    "resultPicture = Image.new('RGBA', imageA.size, (0, 0, 0, 0))\n",
    "\n",
    "resultPicture.paste(imageA,(0,0))\n",
    "resultPicture.paste(newimageB, (0,0), newimageB)\n",
    "resultPicture.show()\n",
    "resultPicture.save(\"./output/result.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and add Logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "SQUARE_FIT_SIZE = 300\n",
    "LOGO_FILENAME = 'input/catlogo.png'\n",
    "logoIm = Image.open(LOGO_FILENAME)\n",
    "logoWidth, logoHeight = logoIm.size\n",
    "os.makedirs('withLogo', exist_ok=True)\n",
    "\n",
    "# Loop over all files in the working directory.\n",
    "for filename in os.listdir('.'):\n",
    "    if not (filename.lower().endswith('.png') or filename.lower().endswith('.jpg')\n",
    "            or filename.lower().endswith('.gif') or filename.lower().endswith('bmp')) \\\n",
    "        or filename == LOGO_FILENAME:\n",
    "        continue # skip non-image files and the logo file itself\n",
    "\n",
    "    im = Image.open(filename)\n",
    "    width, height = im.size\n",
    "\n",
    "    # Check if image needs to be resized.\n",
    "    if width > SQUARE_FIT_SIZE and height > SQUARE_FIT_SIZE:\n",
    "        # Calculate the new width and height to resize to.\n",
    "        if width > height:\n",
    "            height = int((SQUARE_FIT_SIZE / width) * height)\n",
    "            width = SQUARE_FIT_SIZE\n",
    "        else:\n",
    "            width = int((SQUARE_FIT_SIZE / height) * width)\n",
    "            height = SQUARE_FIT_SIZE\n",
    "\n",
    "    # Resize the image.\n",
    "    print('Resizing %s...' % (filename))\n",
    "    im = im.resize((width, height))\n",
    "\n",
    "    # Add the logo if it fits properly in image.\n",
    "    imWidth, imHeight = im.size\n",
    "    if imWidth < logoWidth * 2 and imHeight < logoHeight * 2:\n",
    "        print(\"Logo taking up too much space in image so skipped..\")\n",
    "    else:\n",
    "        print('Adding logo to %s...' % (filename))\n",
    "        im.paste(logoIm, (width - logoWidth, height - logoHeight), logoIm)\n",
    "\n",
    "    # Save changes.\n",
    "    im.save(os.path.join('withLogo', filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('input/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dr. Xavier Chelladurai\n",
    "#06 April 2020\n",
    "#Program to load a color picture and find shape\n",
    "import face_recognition\n",
    "photo_xavi = face_recognition.load_image_file('./xavier/xavier01.png','L')\n",
    "photo_alwy = face_recognition.load_image_file('./alwyn/alwyn01.jpeg','L')\n",
    "photo_arun = face_recognition.load_image_file('./arun/arun01.jpeg','L')\n",
    "print(\"The shapes of the bw photo files are...\")\n",
    "print(\"Xavier Photo....\",photo_xavi.shape)\n",
    "print(\"Alwyn Photo.....\", photo_alwy.shape)\n",
    "print(\"Arun Photo......\", photo_arun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "photo_xavi = face_recognition.load_image_file('./xavier/xavier01.png','RGB')\n",
    "photo_alwy = face_recognition.load_image_file('./alwyn/alwyn01.jpeg','RGB')\n",
    "photo_arun = face_recognition.load_image_file('./arun/arun01.jpeg')\n",
    "print(\"The shapes of the Color photo files are...\")\n",
    "print(\"Xavier Photo....\",photo_xavi.shape)\n",
    "print(\"Alwyn Photo.....\", photo_alwy.shape)\n",
    "print(\"Arun Photo......\", photo_arun.shape)\n",
    "pil_image_xavi = Image.fromarray(photo_xavi)\n",
    "pil_image_xavi.show()\n",
    "pil_image_alwy = Image.fromarray(photo_alwy)\n",
    "pil_image_alwy.show()\n",
    "pil_image_arun = Image.fromarray(photo_arun)\n",
    "pil_image_arun.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)\n",
    "    \n",
    "# Module 5 Display Attendance Module\n",
    "pil_uk = Image.fromarray(uk)\n",
    "draw = ImageDraw.Draw(pil_uk)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 60)\n",
    "\n",
    "if emp_index ==-1:\n",
    "    name =\"Face NOT Recognized\"\n",
    "else:\n",
    "    name = firstname[emp_index]+\" \"+lastname[emp_index]\n",
    "x = 100\n",
    "y = uk.shape[0] - 100\n",
    "draw.text((x, y), name, font=fnt, fill=(250,0,0))\n",
    "pil_uk.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "xavi_photo = face_recognition.load_image_file('./xavier/xavier01.png')\n",
    "print(xavi_photo.shape)\n",
    "l = face_recognition.face_locations(xavi_photo, model = 'hog')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "xavi_face = xavi_photo[top:bottom, left:right]\n",
    "print(xavi_face.shape)\n",
    "xavi_face_image = Image.fromarray(xavi_face)\n",
    "xavi_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)\n",
    "    \n",
    "# Module 5 Display Attendance Module\n",
    "pil_uk = Image.fromarray(uk)\n",
    "draw = ImageDraw.Draw(pil_uk)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 60)\n",
    "\n",
    "if emp_index ==-1:\n",
    "    name =\"Face NOT Recognized\"\n",
    "else:\n",
    "    name = firstname[emp_index]+\" \"+lastname[emp_index]\n",
    "x = 100\n",
    "y = uk.shape[0] - 100\n",
    "draw.text((x, y), name, font=fnt, fill=(0,0,0))\n",
    "pil_uk.show()\n",
    "\n",
    "# Module 6 Announce Attendance Recorded Module\n",
    "audioloc = audiolocation[emp_index]\n",
    "pygame.mixer.init()\n",
    "if emp_index ==-1:\n",
    "    pygame.mixer.music.load(\n",
    "        \"./DataFiles/EmployeeAudio/failure.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "else:\n",
    "    pygame.mixer.music.load(audioloc)\n",
    "    pygame.mixer.music.play()\n",
    "    pygame.mixer.music.queue(\n",
    "        \"./DataFiles/EmployeeAudio/success.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./DataFiles/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "uk =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        uk_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, uk_encode, tolerance = 0.5)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "\n",
    "emp_index = identify_employee(uk)    \n",
    "print(emp_index)   \n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./DataFiles/Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)\n",
    "    \n",
    "# Module 5 Display Attendance Module\n",
    "pil_uk = Image.fromarray(uk)\n",
    "draw = ImageDraw.Draw(pil_uk)\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 60)\n",
    "\n",
    "if emp_index ==-1:\n",
    "    name =\"Face NOT Recognized\"\n",
    "else:\n",
    "    name = firstname[emp_index]+\" \"+lastname[emp_index]\n",
    "x = 100\n",
    "y = uk.shape[0] - 100\n",
    "draw.text((x, y), name, font=fnt, fill=(0,0,0))\n",
    "pil_uk.show()\n",
    "\n",
    "# Module 6 Announce Attendance Recorded Module\n",
    "audioloc = audiolocation[emp_index]\n",
    "pygame.mixer.init()\n",
    "if emp_index ==-1:\n",
    "    pygame.mixer.music.load(\n",
    "        \"./DataFiles/EmployeeAudio/failure.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "else:\n",
    "    pygame.mixer.music.load(audioloc)\n",
    "    pygame.mixer.music.play()\n",
    "    pygame.mixer.music.queue(\n",
    "        \"./DataFiles/EmployeeAudio/success.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "family_photo = face_recognition.load_image_file(\"./group/gr010.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(family_photo, model=\"hog\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = family_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "xavi_photo = face_recognition.load_image_file('./xavier/xavier01.png')\n",
    "print(xavi_photo.shape)\n",
    "l = face_recognition.face_locations(xavi_photo, model ='cnn')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "xavi_image = xavi_photo[top:bottom, left:right]\n",
    "print(xavi_image.shape)\n",
    "xavi_face_image = Image.fromarray(xavi_image)\n",
    "xavi_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "xavi_photo = face_recognition.load_image_file('./xavier/xavier01.png')\n",
    "print(xavi_photo.shape)\n",
    "l = face_recognition.face_locations(xavi_photo)\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "xavi_face = xavi_photo[top:bottom, left:right]\n",
    "print(xavi_face.shape)\n",
    "xavi_face_image = Image.fromarray(xavi_face)\n",
    "#xavi_face_image.show()\n",
    "xavi_photo_image = Image.fromarray(xavi_photo)\n",
    "draw = ImageDraw.Draw(xavi_photo_image)\n",
    "draw.rectangle(\n",
    "   (left, top, right, bottom),\n",
    "   outline = (0, 0, 255), width = 5)\n",
    "xavi_photo_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "xavi_photo = face_recognition.load_image_file('./xavier/xavier01.png')\n",
    "print(xavi_photo.shape)\n",
    "l = face_recognition.face_locations(xavi_photo)\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "\n",
    "#xavi_face_image.show()\n",
    "\n",
    "fnt = ImageFont.truetype(\"Pillow/Tests/fonts/Times New Roman\", 60)\n",
    "xavi_photo_image = Image.fromarray(xavi_photo)\n",
    "draw = ImageDraw.Draw(xavi_photo_image)\n",
    "draw.rectangle(\n",
    "   (left, top, right, bottom),\n",
    "   outline=(0, 0, 255), width = 4)\n",
    "draw.text((left+100,bottom - 50), \"Xavier\", font=fnt, fill=(255,0,0))\n",
    "xavi_photo_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "family_photo = face_recognition.load_image_file(\"./group/gr010.jpeg\")\n",
    "\n",
    "# Convert the group photo into a PIL Image\n",
    "family_pil_image = Image.fromarray(family_photo)\n",
    "\n",
    "# Find all the faces in the image \n",
    "fl = face_recognition.face_locations(family_photo)\n",
    "draw = ImageDraw.Draw(family_pil_image)\n",
    "\n",
    "\n",
    "# Let us print the number of faces in the Photo\n",
    "face_count = len(fl)\n",
    "print(\"No of Faces detected in this photo\", face_count)\n",
    "\n",
    "for i in range(face_count):\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = fl[i]\n",
    "    print(\"Face,,\", i, \" Top, Left, , Bottom, Right..\", top, left, bottom, right)\n",
    "    # You can access the actual face itself like this:\n",
    "    draw.rectangle(\n",
    "            (left, top, right, bottom),\n",
    "            outline=(255, 0, 0), width=3)\n",
    "        \n",
    "family_pil_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "family_photo = face_recognition.load_image_file(\"./group/gr010.jpeg\")\n",
    "\n",
    "# Convert the group photo into a PIL Image\n",
    "family_pil_image = Image.fromarray(family_photo)\n",
    "\n",
    "# Find all the faces in the image \n",
    "fl = face_recognition.face_locations(family_photo)\n",
    "# Let us print the number of faces in the Photo\n",
    "face_count = len(fl)\n",
    "print(\"No of Faces detected in this photo\", face_count)\n",
    "\n",
    "draw = ImageDraw.Draw(family_pil_image)\n",
    "\n",
    "fnt = ImageFont.truetype(\"Pillow/Tests/fonts/Times New Roman\", 20)\n",
    "# Let us print the number of faces in the Photo\n",
    "\n",
    "for i in range(face_count):\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = fl[i]\n",
    "    print(\"Face,,\", i, \" Top, Left, , Bottom, Right..\", top, left, bottom, right)\n",
    "    # You can access the actual face itself like this:\n",
    "    draw.rectangle(\n",
    "            (left, top, right, bottom),\n",
    "            outline=(255, 0, 0), width = 3)\n",
    "    draw.text((left,bottom-20), str(i), font=fnt, fill=(0,0,255))   \n",
    "family_pil_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "photo_xavi = face_recognition.load_image_file('./xavier/xavier01.png','RGB')\n",
    "encodings_xavi = face_recognition.face_encodings(photo_xavi)[0]\n",
    "print(\"The shapes of the Encoding array is ...\", encodings_xavi.shape)\n",
    "print(\"Now let us print the encoding\")\n",
    "print(encodings_xavi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "photo_gr = face_recognition.load_image_file('./group/gr009.jpeg','RGB')\n",
    "encodings_gr = face_recognition.face_encodings(photo_gr)\n",
    "print(\"The Number of faces  ...\", len(encodings_gr))\n",
    "print(\"The shape of each encodings..\", encodings_gr[0].shape)\n",
    "print(\"Now let us print the encoding\")\n",
    "for i in range(len(encodings_gr)):\n",
    "    print(\" Encodings of Face...\", i)\n",
    "    print(encodings_gr[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "photo_xavi01 = face_recognition.load_image_file('./xavier/xavier01.png','RGB')\n",
    "encodings_xavi01 = face_recognition.face_encodings(photo_xavi01)[0]\n",
    "\n",
    "photo_alwy01 = face_recognition.load_image_file('./alwyn/alwyn01.jpeg','RGB')\n",
    "encodings_alwy01 = face_recognition.face_encodings(photo_alwy01)[0]\n",
    "dist = face_recognition.face_distance([encodings_xavi01],encodings_alwy01)\n",
    "print(\"Distance between the two photos \", dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "fa = face_recognition.load_image_file('./known/Anil.jpeg','RGB')\n",
    "f0 = face_recognition.load_image_file('./known/Bill.jpeg','RGB')\n",
    "f1 = face_recognition.load_image_file('./known/Mukesh.jpeg','RGB')\n",
    "f2 = face_recognition.load_image_file('./known/Surya.jpeg','RGB')\n",
    "f3 = face_recognition.load_image_file('./known/Vikram.jpeg','RGB')\n",
    "\n",
    "fa_sign = face_recognition.face_encodings(fa)[0]\n",
    "f0_sign = face_recognition.face_encodings(f0)[0]\n",
    "f1_sign = face_recognition.face_encodings(f1)[0]\n",
    "f2_sign = face_recognition.face_encodings(f2)[0]\n",
    "f3_sign = face_recognition.face_encodings(f3)[0]\n",
    "\n",
    "\n",
    "faces = [f0_sign, f1_sign, f2_sign, f3_sign ]\n",
    "d = face_recognition.face_distance(faces,fa_sign)\n",
    "print(\"Distance: Anil to Bill, Mukesh, Surya,  and Vikram respectively\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "photo_xavi01 = face_recognition.load_image_file('./xavier/xavier01.png','RGB')\n",
    "photo_xavi02 = face_recognition.load_image_file('./xavier/xavier02.jpg','RGB')\n",
    "photo_xavi03 = face_recognition.load_image_file('./xavier/xavier03.png','RGB')\n",
    "#Let us find the encodings for each of the three faces\n",
    "encodings_xavi01 = face_recognition.face_encodings(photo_xavi01)[0]\n",
    "encodings_xavi02 = face_recognition.face_encodings(photo_xavi02)[0]\n",
    "encodings_xavi03 = face_recognition.face_encodings(photo_xavi03)[0]\n",
    "# Let us find the distance between xavier01.png to xavier02.jpg\n",
    "dist01_02 = face_recognition.face_distance([encodings_xavi01],encodings_xavi02)\n",
    "dist02_03 = face_recognition.face_distance([encodings_xavi02],encodings_xavi03)\n",
    "dist03_01 = face_recognition.face_distance([encodings_xavi03],encodings_xavi01)\n",
    "print(\"Distance 1 to 2 \", dist01_02)\n",
    "print(\"Distance 2 to 3 \", dist02_03)\n",
    "print(\"Distance 3 to 1 \", dist03_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "photo_indr01 = face_recognition.load_image_file('./Gandhis/indra01.jpeg','RGB')\n",
    "photo_indr02 = face_recognition.load_image_file('./Gandhis/indra02.jpg','RGB')\n",
    "photo_priy01 = face_recognition.load_image_file('./Gandhis/priyanka01.jpg','RGB')\n",
    "photo_priy02 = face_recognition.load_image_file('./Gandhis/priyanka02.jpeg','RGB')\n",
    "photo_sonia01 = face_recognition.load_image_file('./Gandhis/sonia01.jpeg','RGB')\n",
    "encodings_indr01 = face_recognition.face_encodings(photo_indr01)[0]\n",
    "encodings_indr02 = face_recognition.face_encodings(photo_indr02)[0]\n",
    "encodings_priy01 = face_recognition.face_encodings(photo_priy01)[0]\n",
    "encodings_priy02 = face_recognition.face_encodings(photo_priy02)[0]\n",
    "encodings_sonia01 = face_recognition.face_encodings(photo_sonia01)[0]\n",
    "print(\"Distance: Priyanka01 to indr01, indr02, soni01, pri02 respectively\")\n",
    "faces = [encodings_indr01, encodings_indr02, encodings_sonia01, encodings_priy02 ]\n",
    "print(face_recognition.face_distance(faces,encodings_priy01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "n = 6\n",
    "photo_mother =[]\n",
    "encodings_mother = []\n",
    "photo_daughter = []\n",
    "encodings_daughter = []\n",
    "for i in range(n):\n",
    "    m_path_template = './mother/mother_0{}.jpg'\n",
    "    m_path = m_path_template.format(i)\n",
    "    photo_mother.append(face_recognition.load_image_file(m_path,'RGB'))\n",
    "    encodings_mother.append(face_recognition.face_encodings(photo_mother[i])[0])\n",
    "    d_path_template = './daughter/daughter_0{}.jpg'\n",
    "    d_path = d_path_template.format(i)\n",
    "    photo_daughter.append(face_recognition.load_image_file(d_path,'RGB'))\n",
    "    encodings_daughter.append(face_recognition.face_encodings(photo_daughter[i])[0])\n",
    "for i in range(6):\n",
    "    a = \"\\nDistance: Daughter {} to Mothers 0, 1, 2, 3, 4, 5\"\n",
    "    print(a.format(i))\n",
    "    print(face_recognition.face_distance(encodings_mother,encodings_daughter[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "image_xav = face_recognition.load_image_file('./known/xavier/xavier.png')\n",
    "xavier_encod = face_recognition.face_encodings(image_xav)[0]\n",
    "\n",
    "image_uk = face_recognition.load_image_file('./unknown/xavier01.png')\n",
    "\n",
    "uk_encod = face_recognition.face_encodings(image_uk)[0]\n",
    "results = face_recognition.compare_faces([xavier_encod], uk_encod, tolerance = 0.5)\n",
    "if results[0]:\n",
    "    print(\"This is Xavier \")\n",
    "else:\n",
    "        print('This is NOT Xavier ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "f0 = face_recognition.load_image_file('./known/Bill.jpeg','RGB')\n",
    "f1 = face_recognition.load_image_file('./known/Karthik.jpeg','RGB')\n",
    "f2 = face_recognition.load_image_file('./known/Mukesh.jpeg','RGB')\n",
    "f3 = face_recognition.load_image_file('./known/Prabhu.jpeg','RGB')\n",
    "f4 = face_recognition.load_image_file('./known/Surya.jpeg','RGB')\n",
    "f5 = face_recognition.load_image_file('./known/Vikram.jpeg','RGB')\n",
    "fuk = face_recognition.load_image_file('./unknown/uk02.jpeg','RGB')\n",
    "\n",
    "fuk_sign = face_recognition.face_encodings(fuk)[0]\n",
    "f0_sign = face_recognition.face_encodings(f0)[0]\n",
    "f1_sign = face_recognition.face_encodings(f1)[0]\n",
    "f2_sign = face_recognition.face_encodings(f2)[0]\n",
    "f3_sign = face_recognition.face_encodings(f3)[0]\n",
    "f4_sign = face_recognition.face_encodings(f4)[0]\n",
    "f5_sign = face_recognition.face_encodings(f5)[0]\n",
    "\n",
    "faces = [f0_sign, f1_sign, f2_sign, f3_sign, f4_sign, f5_sign ]\n",
    "\n",
    "fnd = face_recognition.compare_faces(faces,fuk_sign, tolerance = 0.5)\n",
    "\n",
    "print(\"Compare Matches:Bill, Karthik, Mukesh, Prabhu, Surya, Vikram\")\n",
    "print(fnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import face_recognition\n",
    "f = pd.read_csv('./Data File/Employee.csv')\n",
    "print(f.to_string())\n",
    "empno = f[\"Employee No\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "uk = face_recognition.load_image_file(\"./unknown/uk01.jpeg\")\n",
    "uk_encod = face_recognition.face_encodings(uk)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "found = face_recognition.compare_faces(emp_encod, uk_encod, tolerance = 0.5)    \n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "fnt = ImageFont.truetype(\n",
    "    \"Pillow/Tests/fonts/Arial\", 60)\n",
    "\n",
    "f = pd.read_csv('./Data File/Employee.csv')\n",
    "\n",
    "print(f.to_string())\n",
    "empno = f[\"Employee No\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "uk = face_recognition.load_image_file(\"opencv5.png\")\n",
    "print(uk.shape)\n",
    "uk_encod = face_recognition.face_encodings(uk)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "    \n",
    "found = face_recognition.compare_faces(emp_encod,uk_encod, tolerance = 0.5)    \n",
    "print(found)\n",
    "for i in range(n):\n",
    "    if found[i]:\n",
    "    \n",
    "        left = 100\n",
    "        bottom = uk.shape[0]\n",
    "        pil_uk = Image.fromarray(uk)\n",
    "        draw = ImageDraw.Draw(pil_uk)\n",
    "        draw.text((left,bottom - 250), name[i], font=fnt, fill=(0,0,0))\n",
    "        pil_uk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APOD Viewer\n",
    "#Icon CC Attribution 3.0 Unported\n",
    "import tkinter, requests, webbrowser\n",
    "from tkcalendar import DateEntry #To use with auto-py-to-exe add hidden imports of bablel.numbers\n",
    "from PIL import ImageTk, Image\n",
    "from io import BytesIO\n",
    "from tkinter import Toplevel, filedialog\n",
    "\n",
    "#Define window\n",
    "root = tkinter.Tk()\n",
    "root.title('APOD Photo Viewer')\n",
    "root.iconbitmap('rocket.ico')\n",
    "\n",
    "#Define fonts and colors\n",
    "nasa_blue = \"#043c93\"\n",
    "nasa_light_blue = \"#7AA5D3\"\n",
    "nasa_red = \"#ff1923\"\n",
    "nasa_white = \"#ffffff\"\n",
    "text_font = ('Times New Roman', 14)\n",
    "root.config(bg=nasa_blue)\n",
    "\n",
    "#Define functions\n",
    "def get_request():\n",
    "    '''Get request data from nasa Astronomy Picture of the Day API'''\n",
    "    global response\n",
    "\n",
    "    #Example request\n",
    "    '''{'copyright': 'Declan Deval', 'date': '2020-07-14', 'explanation': 'Have you ever seen a comet? Tonight -- and likely the next few nights -- should be a good chance. \n",
    "    Go outside just at sunset and look to your northwest.  The lower your horizon, the better.  Binoculars may help, but if your sky is cloudless and dark, \n",
    "    all you should need is your unaided eyes and patience. As the Sun sets, the sky will darken, and there will be an unusual faint streak pointing diagonally near the \n",
    "    horizon. That is Comet NEOWISE. It is a 5-kilometer-wide evaporating dirty iceberg visiting from -- and returning to -- the outer Solar System. As the Earth turns, \n",
    "    the comet will soon set, so you might want to take a picture. In the featured image, Comet C/2020 F3 (NEOWISE) was captured two mornings ago rising over Stonehenge \n",
    "    in the UK.  Discovered with the NASA satellite NEOWISE toward the end of March, Comet NEOWISE has surprised many by surviving its closest approach to the Sun, \n",
    "    brightening dramatically, and developing impressive (blue) ion and (white) dust tails.    \n",
    "    Notable Images of Comet NEOWISE Submitted to APOD:  || July 13  || July 12  || July 11  || July 10 & earlier ||', \n",
    "    'hdurl': 'https://apod.nasa.gov/apod/image/2007/NeowiseStonehenge_Deval_5572.jpg', 'media_type': 'image', 'service_version': 'v1', \n",
    "    'title': 'Comet NEOWISE over Stonehenge', 'url': 'https://apod.nasa.gov/apod/image/2007/NeowiseStonehenge_Deval_960.jpg'}'''\n",
    "\n",
    "    #Set the parameters for the request\n",
    "    url = 'https://api.nasa.gov/planetary/apod'\n",
    "    #api_key = 'N0NN5ebP8B13oGp7GFSvj61aeuAlX2urJEKExjhc'\n",
    "    api_key = 'DEMO_KEY'\n",
    "    date = calander.get_date()\n",
    "    #date = date_entry.get()\n",
    "\n",
    "    #USE YOUR OWN API KEY!\n",
    "    querystring = {'api_key':api_key, 'date':date}\n",
    "\n",
    "    #Call the request and turn it into a python format\n",
    "    response = requests.request(\"GET\", url, params=querystring)\n",
    "    response = response.json()\n",
    "\n",
    "    set_info()\n",
    "\n",
    "\n",
    "def set_info():\n",
    "    \"\"\"Update output lables based on API call\"\"\"   \n",
    "    #Update the picture text and date\n",
    "    picture_date.config(text=response['date'], font=text_font, bg=nasa_white)\n",
    "    picture_explanation.config(text=response['explanation'], font=text_font, bg=nasa_white)\n",
    "\n",
    "    #We need to use these 3 images in other functions so make them global\n",
    "    #Also Tkinter's garbage collector removes photos inside functions if not global\n",
    "    global img\n",
    "    global full_img\n",
    "    global thumb\n",
    "\n",
    "    #Grab the photo that is stored in the previous request.  Stream=True sets for automatic download\n",
    "    url = response['url']\n",
    "    img_response = requests.get(url, stream=True)\n",
    "\n",
    "    if response['media_type'] == 'image':\n",
    "        #Get the content of the response and use BytesIO to open it as an image.\n",
    "        #Keep a reference to this as this is what you can use to save (Image not PhotoImage)\n",
    "        #Create the full screen image for the second window\n",
    "        img_data = img_response.content\n",
    "        img = Image.open(BytesIO(img_data))\n",
    "        full_img = ImageTk.PhotoImage(img)\n",
    "\n",
    "        #Create the thumbnail for the main screen\n",
    "        thumb_data = img_response.content\n",
    "        thumb = Image.open(BytesIO(img_data))\n",
    "        thumb.thumbnail((200,200))\n",
    "        thumb = ImageTk.PhotoImage(thumb)\n",
    "\n",
    "        #Set the thumnail image\n",
    "        picture_label.config(image=thumb)\n",
    "    else:\n",
    "        #WE have a link to a video...open the video (try july 1st, 2020)\n",
    "        picture_label.config(image='')\n",
    "        picture_label.config(text=url)\n",
    "        webbrowser.open(url)\n",
    "\n",
    "\n",
    "def full_photo():\n",
    "    \"\"\"Open the full size photo in a new window\"\"\"\n",
    "    #global full_img\n",
    "\n",
    "    top = Toplevel()\n",
    "    img_label = tkinter.Label(top, image=full_img)\n",
    "    img_label.pack()\n",
    "\n",
    "\n",
    "def save_photo():\n",
    "    \"\"\"Save the desired photo\"\"\"\n",
    "    #global img\n",
    "    save_name = filedialog.asksaveasfilename(initialdir=\"./\", title=\"Save Image\", filetypes=((\"JPEG\",\"*.jpg\"),(\"All Files\",\"*.*\")))\n",
    "    img.save(save_name + \".jpg\")\n",
    "\n",
    "\n",
    "#Define GUI Layout\n",
    "#Create frames\n",
    "input_frame = tkinter.Frame(root, bg=nasa_blue)\n",
    "output_frame = tkinter.Frame(root, bg=nasa_white)\n",
    "input_frame.pack()\n",
    "output_frame.pack(padx=50, pady=(0,25))\n",
    "\n",
    "#Layout for input frame\n",
    "calander = DateEntry(input_frame, width=10,  font=text_font, background=nasa_blue, foreground=nasa_white)\n",
    "#date_entry = tkinter.Entry(input_frame, width=10)\n",
    "submit_button = tkinter.Button(input_frame, text=\"Submit\", font=text_font, bg=nasa_light_blue, command=get_request)\n",
    "full_button = tkinter.Button(input_frame, text='Full Photo', font=text_font, bg=nasa_light_blue, command=full_photo)\n",
    "save_button = tkinter.Button(input_frame, text=\"Save Photo\", font=text_font, bg=nasa_light_blue, command=save_photo)\n",
    "quit_button = tkinter.Button(input_frame, text=\"Exit\", font=text_font, bg=nasa_red,command=root.destroy)\n",
    "\n",
    "calander.grid(row=0, column=0, padx=5, pady=10)\n",
    "#date_entry.grid(row=0, column=0)\n",
    "submit_button.grid(row=0, column=1, padx=5, pady=10, ipadx=35)\n",
    "full_button.grid(row=0, column=2, padx=5, pady=10, ipadx=25)\n",
    "save_button.grid(row=0, column=3, padx=5, pady=10, ipadx=20)\n",
    "quit_button.grid(row=0, column=4, padx=5, pady=10, ipadx=50)\n",
    "\n",
    "#Layout for output frame\n",
    "picture_date = tkinter.Label(output_frame)\n",
    "picture_explanation = tkinter.Label(output_frame, wraplength=600)\n",
    "picture_label = tkinter.Label(output_frame)\n",
    "\n",
    "picture_explanation.grid(row=0, column=0, rowspan=2, padx=10, pady=10) \n",
    "picture_label.grid(row=0, column=1, padx=10, pady=10)\n",
    "picture_date.grid(row=1, column=1, padx=10)\n",
    "\n",
    "#Call get_request() so you always start with a photo and explination\n",
    "get_request()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as FaceRec\n",
    "import PIL.Image as MyPilImg\n",
    "import PIL.ImageDraw as MyPilImgDraw\n",
    "\n",
    "# ------------load image ----------------\n",
    "ImageArray = FaceRec.load_image_file(\"Pics/me_2021.jpg\")\n",
    "# -------- Find all facial features in all the faces in the image----\n",
    "face_landmarks_list = FaceRec.face_landmarks(ImageArray)\n",
    "# -------- Load pillow image from Numpy array --------\n",
    "PilImage = MyPilImg.fromarray(ImageArray)\n",
    "# ---------------\n",
    "draw = MyPilImgDraw.Draw(PilImage, 'RGBA')\n",
    "# ------------------------------------\n",
    "for face_landmark in face_landmarks_list:\n",
    "    # --------- add rouge makeup for lips!--------\n",
    "    draw.polygon(face_landmark[\"top_lip\"], fill=(150, 0, 0, 64))#-0:255\n",
    "    draw.polygon(face_landmark[\"bottom_lip\"], fill=(150, 0, 0, 64))\n",
    "    #-----\n",
    "    #draw.line(face_landmark ['top_lip'], fill=(150, 0, 0, 30), width=6)\n",
    "    #draw.line(face_landmark ['bottom_lip'], fill=(150, 0, 0, 30), width=6)\n",
    "    # ----------Thicker eyebrows ! --------------\n",
    "    draw.polygon(face_landmark ['left_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    draw.polygon(face_landmark ['right_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    #draw.line(face_landmark ['left_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "    #draw.line(face_landmark ['right_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "    # -------- Apply some eyeliner------------------\n",
    "    draw.line(face_landmark['left_eye'], fill=(0, 0, 0, 110), width=2)\n",
    "    draw.line(face_landmark['right_eye'], fill=(0, 0, 0, 110), width=2)\n",
    "\n",
    "     # --------sparkle on the eyes------------\n",
    "    draw.polygon(face_landmark ['left_eye'], fill=(255, 255, 255, 90))\n",
    "    draw.polygon(face_landmark ['right_eye'], fill=(255, 255, 255, 90))\n",
    "\n",
    "#----Show and save image --------------------------\n",
    "PilImage.show()\n",
    "PilImage.save(\"Out/me_makeup.jpg\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as FaceRec\n",
    "import PIL.Image as MyPilImg\n",
    "import  PIL.ImageDraw as MyPilImgDraw\n",
    "\n",
    "#------------load image ----------------\n",
    "ImageArray=FaceRec.load_image_file(\"Pics/team2.jpg\")\n",
    "#-------- detect faces --------------------\n",
    "face_locations=FaceRec.face_locations(ImageArray)\n",
    "print(face_locations)\n",
    "#-------- Load pillow image from Numpy array --------\n",
    "PilAllFacesImage=MyPilImg.fromarray(ImageArray)\n",
    "#-----------\n",
    "#-------- Find location of faces in image & draw rectangle ----\n",
    "n=1\n",
    "for face in face_locations:\n",
    "    # ----------------\n",
    "    top,right,bottom,left=face\n",
    "    #----------------\n",
    "    print(f\"Top:{top} , Right:{right} , Bottom:{bottom} , Left:{left}\")\n",
    "    #-------------------------\n",
    "    FaceImage=ImageArray[top:bottom,left:right]\n",
    "    PilFaceImage=MyPilImg.fromarray(FaceImage)\n",
    "    #PilFaceImage.show()\n",
    "    PilFaceImage.save(\"Out/face_\"+str(n)+\".jpg\")# => face_1.jpg\n",
    "    n=n+1\n",
    "    # ------------------------\n",
    "    # ------draw rect----------\n",
    "    draw = MyPilImgDraw.Draw(PilAllFacesImage)\n",
    "    draw.rectangle([right, top, left, bottom], outline=\"red\", width=5)  # [ right , top , left , bottom\n",
    "    # ------------------------\n",
    "#-------- Show and save image -----------------------\n",
    "PilAllFacesImage.show()\n",
    "#PilImage.thumbnail((700,700)) #Optional\n",
    "PilAllFacesImage.save(\"Out/all_faces.jpg\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as FaceRec\n",
    "import PIL.Image as MyPilImg\n",
    "import  PIL.ImageDraw as MyPilImgDraw\n",
    "#-----------------------\n",
    "#------------load image ----------------\n",
    "ImageArray=FaceRec.load_image_file(\"Pics/team2.jpg\")\n",
    "#-------- Find all facial features in all the faces in the image----\n",
    "face_landmarks_list=FaceRec.face_landmarks(ImageArray)\n",
    "#----\n",
    "#-------- Load pillow image from Numpy array --------\n",
    "PilImage=MyPilImg.fromarray(ImageArray)\n",
    "#---------------\n",
    "draw = MyPilImgDraw.Draw(PilImage)\n",
    "#------------------------------------\n",
    "#print(face_landmarks_list)\n",
    "for face_landmark in face_landmarks_list:\n",
    "    #print(face_landmark)\n",
    "    for facial_feature in face_landmark.keys():\n",
    "        #print(facial_feature)\n",
    "        face_feature_loc=face_landmark[facial_feature]\n",
    "        draw.line(face_feature_loc,width=5,fill=\"white\")\n",
    "\n",
    "#----Show and save image --------------------------\n",
    "PilImage.show()\n",
    "PilImage.save(\"Out/me_landmarks.jpg\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
