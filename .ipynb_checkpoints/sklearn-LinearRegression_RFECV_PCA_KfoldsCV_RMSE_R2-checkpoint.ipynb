{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis(PCA)  主成分分析：特徵擷取的一種方法\n",
    "\n",
    "為降維(Dimension reduction)內特徵擷取(Feature extraction)的一種方法，降維就是希望資料的維度數減少，但整體的效能不會差異太多甚至會更好，降維（Dimensionality Reduction）是一種無監督學習，其最主要的目的是「化繁為簡」：將原本高維的數據（比方說 N 維）重新以一個相較低維的形式表達（比方說 K 維，且 K<N）。理想上只要該 K 維的表徵（representation）具有代表性，能夠抓住原來 N 維數據的大部分特性，我們就能在沒有損失什麼資訊的情況下，用更簡潔的方式呈現該組數據，進而對其本質有更深的理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 7) #指定降維\n",
    "Xtrain = pca.fit_transform(Xtrain)\n",
    "Xtest = pca.transform(Xtest)\n",
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(Xtrain , Ytrain)\n",
    "model.score(Xtest , Ytest) #測試與驗證"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉驗證(Cross validation)\n",
    "一般來說我們會將數據分為兩個部分，一部分用來訓練，一部分用來測試，交叉驗證是一種統計學上將樣本切割成多個小子集的做測試與訓練。交叉驗證主要分為以下幾類：\n",
    "\n",
    "- k-folder cross-vailation\n",
    "- kk folder cross-vaildation\n",
    "- least-one-out cross-validation\n",
    "- 10-fold corss validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "k_fold = KFold(n_splits=5) #訓練了模型5次\n",
    "test_scores = []\n",
    "for train_idx , test_idx in k_fold.split(X):\n",
    "    Xtrain = X[train_idx]\n",
    "    Ytrain = Y[train_idx]\n",
    "\n",
    "    Xtest = X[test_idx]\n",
    "    Ytest = Y[test_idx]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(Xtrain , Ytrain)\n",
    "\n",
    "    test_scores.append(model.score(Xtest , Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均值決定了我們的全局分數，這意味著我們可以確信該模型的實時性能在這個數據集上就會出現。\n",
    "# 0.76678 比我們之前的 0.7497 好\n",
    "\n",
    "print(\" mean score of k folds : \" , np.mean(test_scores))\n",
    "plt.plot(test_scores)\n",
    "plt.plot([np.mean(test_scores)]*len(test_scores))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = W.X + c\n",
    "model.coef_.dot(Xtest[10,:]) + model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(Xtest[10,:].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import inv_boxcox\n",
    "transformed_data = inv_boxcox(Y , lam)\n",
    "transformed_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指標定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(y_test , y_pred):\n",
    "    value = (1/len(y_test))*np.sum((y_test - y_pred)**2)\n",
    "    return np.sqrt(value)\n",
    "\n",
    "def r2_score(y_test , y_pred):\n",
    "    ssr = (1/len(y_test))*np.sum((y_test - y_pred)**2)\n",
    "    sst = (1/len(y_test))*np.sum((y_test - np.mean(y_test))**2)\n",
    "    return (1 - (ssr/sst))\n",
    "\n",
    "def mae(y_test , y_pred):\n",
    "    return (1/len(y_test))*np.sum(np.abs(y_test - y_pred))\n",
    "\n",
    "def adj_r2_score(y_test , y_pred , n_features):\n",
    "    numerator = (1-r2_score(y_test , y_pred))*(len(y_test) - 1)\n",
    "    denominator = len(y_test) - n_features - 1\n",
    "    return 1 - (numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "# Plotting Root mean squared error \n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "r2_adj_scores = []\n",
    "\n",
    "for train_idx , test_idx in k_fold.split(X):\n",
    "    Xtrain = X[train_idx]\n",
    "    Ytrain = Y[train_idx]\n",
    "\n",
    "    Xtest = X[test_idx]\n",
    "    Ytest = Y[test_idx]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(Xtrain , Ytrain)\n",
    "\n",
    "    Ypred = model.predict(Xtest)\n",
    "    rmse_scores.append(rmse_score(Ytest , Ypred))\n",
    "    r2_scores.append(r2_score(Ytest , Ypred))\n",
    "    mae_scores.append(mae(Ytest , Ypred))\n",
    "    r2_adj_scores.append(adj_r2_score(Ytest , Ypred , Xtest.shape[1]))\n",
    "\n",
    "print(\" Average RMSE \" , np.mean(rmse_scores))\n",
    "plt.plot(rmse_scores)\n",
    "plt.plot([np.mean(rmse_scores)]*len(rmse_scores))\n",
    "plt.title(\" RMSE \")\n",
    "plt.show()\n",
    "\n",
    "print(\" Average MAE \" , np.mean(mae_scores))\n",
    "plt.plot(mae_scores)\n",
    "plt.plot([np.mean(mae_scores)]*len(mae_scores))\n",
    "plt.title(\" MAE \")\n",
    "plt.show()\n",
    "\n",
    "print(\" Average R square \" , np.mean(r2_scores))\n",
    "plt.plot(r2_scores)\n",
    "plt.plot([np.mean(r2_scores)]*len(r2_scores))\n",
    "plt.title(\" R square \")\n",
    "plt.show()\n",
    "\n",
    "print(\" Average Adj R square \" , np.mean(r2_adj_scores))\n",
    "plt.plot(r2_adj_scores)\n",
    "plt.plot([np.mean(r2_adj_scores)]*len(r2_adj_scores))\n",
    "plt.title(\" Adj R square \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import inv_boxcox\n",
    "\n",
    "Real_data = inv_boxcox(Y , lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_Y[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
