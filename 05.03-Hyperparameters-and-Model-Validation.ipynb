{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Scikit-Learn简介](05.02-Introducing-Scikit-Learn.ipynb) | [目录](Index.ipynb) | [特征工程](05.04-Feature-Engineering.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/wangyingsm/Python-Data-Science-Handbook/blob/master/notebooks/05.03-Hyperparameters-and-Model-Validation.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and Model Validation\n",
    "\n",
    "# 超參數和模型驗證"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "上一節中，我們學習了應用有監督機器學習模型的基本配方：\n",
    "1. 選擇一個模型類別 Choose a class of model\n",
    "2. 選擇模型超參數 Choose model hyperparameters\n",
    "3. 將模型擬合到訓練數據上 Fit the model to the training data\n",
    "4. 將模型在新數據上進行預測 Use the model to predict labels for new data\n",
    "\n",
    "> The first two pieces of this—the choice of model and choice of hyperparameters—are perhaps the most important part of using these tools and techniques effectively.In order to make an informed choice, we need a way to *validate* that our model and our hyperparameters are a good fit to the data.While this may sound simple, there are some pitfalls that you must avoid to do this effectively.\n",
    "\n",
    "前兩步選擇模型類別和超參數，也許是有效使用這些工具和技術的最關鍵部分。為了作出一個明智的選擇，我們需要一個方式來*驗證*我們的模型和超參數，看它們是否擬合數據集。雖然這個方式聽起來很簡單，但是裡面有很多坑你需要避開。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking about Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation the wrong way\n",
    "\n",
    "### 錯誤的模型驗證\n",
    "\n",
    "> Let's demonstrate the naive approach to validation using the Iris data, which we saw in the previous section.\n",
    "We will start by loading the data:\n",
    "In principle, model validation is very simple: after choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n",
    "\n",
    "原則上，模型驗證非常簡單：選擇了模型類別和它的超參數之後，我們將它應用到一些訓練數據上進行訓練，然後將它的預測值和已知值進行比較。\n",
    "讓我們展示使用鳶尾花數據集來進行模型驗證的一個原始方法，首先導入數據："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next we choose a model and hyperparameters. Here we'll use a *k*-neighbors classifier with ``n_neighbors=1``.\n",
    "This is a very simple and intuitive model that says \"the label of an unknown point is the same as the label of its closest training point:\"\n",
    "\n",
    "下面我們選擇模型和超參數。這裡我們會使用*k近鄰*分類器，超參數`n_neighbors=1`。這是一個非常簡單和直觀的模型，它認為“未知的點的標籤與距離它最近的訓練點的標籤是一樣的”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then we train the model, and use it to predict labels for data we already know: \n",
    "\n",
    "然後我們訓練模型，用訓練好的模型來預測訓練集的標籤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We see an accuracy score of 1.0, which indicates that 100% of points were correctly labeled by our model! As you may have gathered, the answer is no.In fact, this approach contains a fundamental flaw: *it trains and evaluates the model on the same data*.Furthermore, the nearest neighbor model is an *instance-based* estimator that simply stores the training data, and predicts labels by comparing new data to these stored points: except in contrived cases, it will get 100% accuracy *every time!*\n",
    "\n",
    "我們看到準確率是1.0，這表示100%的點都被我們的模型正確標記了。你直覺上應該就能知道答案是否定的。這是個最基本的錯誤：*使用同樣的數據集來訓練和評估性能*，它永遠都會是 100% 的準確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation the right way: Holdout sets\n",
    "\n",
    "### 模型驗證的正確方式：保留部分數據\n",
    "\n",
    "> So what can be done?\n",
    "A better sense of a model's performance can be found using what's known as a *holdout set*: that is, we hold back some subset of the data from the training of the model, and then use this holdout set to check the model performance.\n",
    "This splitting can be done using the ``train_test_split`` utility in Scikit-Learn:\n",
    "\n",
    "那麼應該怎麼做？將一部分數據集*保留*出來不參與訓練，並使用它們對模型的性能進行評估才是正確的辦法：意思就是我們將數據中的部分子集從訓練集中分離出來，然後再將它們預測的結果和預先標記的結果進行對比得到模型性能。這可以通過Scikit-Learn的`train_test_split`工具完成："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We see here a more reasonable result: the nearest-neighbor classifier is about 90% accurate on this hold-out set.\n",
    "The hold-out set is similar to unknown data, because the model has not \"seen\" it before.\n",
    "\n",
    "這樣我們就得到了一個更加合理的結果：最近鄰分類器在這樣劃分了訓練集和測試集後，能得到大約90%的準確率。這裡保留出的子數據集類似未知的數據，因為模型根本沒有*見過*它們。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0, train_size=0.5) # 按照50%分成訓練集和測試集\n",
    "model.fit(X1, y1) # 使用訓練集對模型進行擬合\n",
    "\n",
    "# 使用模型對測試集進行預測，並評估結果\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> cross-validation：One disadvantage of using a holdout set for model validation is that we have lost a portion of our data to the model training.In the above case, half the dataset does not contribute to the training of the model! This is not optimal, and can cause problems – especially if the initial set of training data is small. One way to address this is to use *cross-validation*; that is, to do a sequence of fits where each subset of the data is used both as a training set and as a validation set. Visually, it might look something like this:\n",
    "\n",
    "使用交叉驗證：上面的保留子數據集來驗證模型的方式有一個缺點，那就是我們其中一部分的數據無法參與模型訓練過程。在上面例子中，一半的數據集對於訓練模型沒有任何貢獻。這不是最優化的方式，而且可能導致問題，特別是原始訓練數據規模比較小的情況下。解決這個缺點的方法是使用*交叉驗證*；也就是使用一系列的擬合過程，其中每次擬合的時候都是用完整的數據集，但是不同的訓練集和測試集來進行驗證。下面描繪了這個過程："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/05.03-2-fold-CV.png)\n",
    "[附录中生成图像的代码](06.00-Figure-Code.ipynb#2-Fold-Cross-Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we do two validation trials, alternately using each half of the data as a holdout set. Using the split data from before, we could implement it like this: What comes out are two accuracy scores, which we could combine (by, say, taking the mean) to get a better measure of the global model performance. This particular form of cross-validation is a *two-fold cross-validation*—that is, one in which we have split the data into two sets and used each in turn as a validation set.\n",
    "\n",
    "這裡我們使用兩次驗證過程，每次使用不同的一半數據作為保留的數據集來驗證模型。使用上面分好的數據，我們使用下面的代碼實現：上面輸出了兩個準確率結果，我們可以組合（例如通過取平均值）來獲得更好的全局性能結果。上面這個特殊的交叉驗證過程被稱為*雙重檢查驗證*，也就是我們將數據均分為兩個子數據集，然後依次使用它們作為測試集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, 0.9066666666666666)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We could expand on this idea to use even more trials, and more folds in the data—for example, here is a visual depiction of five-fold cross-validation: Here we split the data into five groups, and use each of them in turn to evaluate the model fit on the other 4/5 of the data. This would be rather tedious to do by hand, and so we can use Scikit-Learn's ``cross_val_score`` convenience routine to do it succinctly:\n",
    "\n",
    "我們可以將這個方法擴展到更多的擬合過程，將數據劃分為更多子集進行更多重訓練驗證，例如下圖是一個五重交叉驗證： 這裡我們將數據分成5組，每次使用其中一組來評估模型，其餘的4/5用來訓練模型。每次都要手動完成這項工作是很無聊的，因此我們可以使用Scikit-Learn的`cross_val_score`工具來直接完成它："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "![](figures/05.03-5-fold-CV.png)\n",
    "[附录中生成图像的代码](06.00-Figure-Code.ipynb#5-Fold-Cross-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scikit-Learn implements a number of useful cross-validation schemes that are useful in particular situations; these are implemented via iterators in the ``cross_validation`` module.\n",
    "For example, we might wish to go to the extreme case in which our number of folds is equal to the number of data points: that is, we train on all points but one in each trial.\n",
    "This type of cross-validation is known as *leave-one-out* cross validation, and can be used as follows:\n",
    "\n",
    "Scikit-Learn實現了許多有用的交叉驗證方案，它們適合於特定的場景；這些方案都是在`model_selection`模塊中實現的。例如，我們可能希望採用一種極端的方案，該方案中數據的分組等於數據的樣本數：也就是說，我們使用除了一個數據點外的其他所有數據進行訓練。這種交叉驗證被成為*leave-one-out*交叉驗證，如下例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores = cross_val_score(model, X, y, cv=LeaveOneOut())\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and the score indicates either successful (1.0) or unsuccessful (0.0) prediction. Taking the mean of these gives an estimate of the error rate: Other cross-validation schemes can be used similarly. For a description of what is available in Scikit-Learn, use IPython to explore the ``sklearn.cross_validation`` submodule, or take a look at Scikit-Learn's online [cross-validation documentation](http://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "\n",
    "因為我們有150個樣本，leave-one-out交叉驗證會得到150個驗證結果，結果只有兩種狀態：驗證成功（1.0）或驗證失敗（0.0）。對上面的結果數組求平均值能得到一個估計的準確率：其他交叉驗證方案也是類似的使用。想要查閱Scikit-Learn中可用的交叉驗證方案，可以使用IPython來瀏覽`sklean.model_selection`模塊或者瀏覽Scikit-Learn在線[交叉驗證文檔](http://scikit-learn.org/stable/modules/cross_validation.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the Best Model\n",
    "\n",
    "核心問題是：評估器是否表現不佳？我們應該如何繼續改進？ 這可能有如下的答案：\n",
    "\n",
    "- 使用一個更加複雜或更加靈活的模型\n",
    "- 使用一個沒那麼複雜或沒那麼靈活的模型\n",
    "- 收集更多的訓練樣本\n",
    "- 對每個樣本收集更多信息，增加特徵\n",
    "\n",
    "> The answer to this question is often counter-intuitive.\n",
    "In particular, sometimes using a more complicated model will give worse results, and adding more training samples may not improve your results!\n",
    "The ability to determine what steps will improve your model is what separates the successful machine learning practitioners from the unsuccessful.\n",
    "\n",
    "對這個問題的解答經常是反直覺的。比方說有時使用一個更複雜的模型可能會得到一個更差的結果，而增加樣本數量不能改進你的結果。決定採用哪些方法步驟來改進模型的能力是成功的機器學習實踐者和不成功的實踐者之間的主要區別。\n",
    "\n",
    "\n",
    "### Analyzing the quality of the fit\n",
    "\n",
    "為了判斷模型好壞能夠看看它的預測能力如何。將我們的模型與我們用來擬合它的相同數據進行比較是一件危險的事情，因為它鼓勵您調整模型以最適合您的數據，而不是嘗試製作一個模型來預測生成數據的過程。使模型適合您的資料被稱為 overfitting (過度擬合)。\n",
    "\n",
    "從數學上講如果多項式次數增加得足夠多，我們就可以擬合任何函數。例如用 15 階多項式擬合數據會創建一個模型，該模型通過大部分點，但清楚地表示底層模型很糟糕，現實世界中通常沒有可用的底層模型，過擬合更難看出，因為它只是表現為“表現良好”的模型。： "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/overfitting.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.745401</td>\n",
       "      <td>3.229269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.507143</td>\n",
       "      <td>14.185654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.319939</td>\n",
       "      <td>9.524231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.986585</td>\n",
       "      <td>6.672066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.560186</td>\n",
       "      <td>-3.358149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x          y\n",
       "0  3.745401   3.229269\n",
       "1  9.507143  14.185654\n",
       "2  7.319939   9.524231\n",
       "3  5.986585   6.672066\n",
       "4  1.560186  -3.358149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "data = read_csv(\"https://milliams.com/courses/applied_data_analysis/linear.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "train.plot.scatter(\"x\", \"y\", color=\"red\", marker=\"o\", ax=ax, label=\"train\")\n",
    "test.plot.scatter(\"x\", \"y\", color=\"blue\", marker=\"x\", ax=ax, label=\"test\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676069631786152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(train[[\"x\"]], train[\"y\"])\n",
    "model.score(test[[\"x\"]], test[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bias-variance trade-off\n",
    "\n",
    "### 偏差方差的權衡\n",
    "\n",
    "> Fundamentally, the question of \"the best model\" is about finding a sweet spot in the tradeoff between *bias* and *variance*. Consider the following figure, which presents two regression fits to the same dataset:\n",
    "\n",
    "“最佳模型”問題根本上是關於尋找*偏差*和*方差*的最佳均衡點。考慮下圖，這是對同一個數據集的兩個回歸："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_data(N=30, err=0.8, rseed=1):\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/05.03-bias-variance.png)\n",
    "[附录中生成图像的代码](06.00-Figure-Code.ipynb#Bias-Variance-Tradeoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The model on the left attempts to find a straight-line fit through the data.\n",
    "Because the data are intrinsically more complicated than a straight line, the straight-line model will never be able to describe this dataset well. Such a model is said to *underfit* the data: that is, it does not have enough model flexibility to suitably account for all the features in the data; another way of saying this is that the model has high *bias*.\n",
    "\n",
    "左邊的模型試圖找出一條直線來擬合數據。因為這個數據很明顯比直線要復雜的多，因此直線模型不可能很好的描述這個數據集。這樣的模型我們稱為“欠擬合 (underfit)”：也就是說，它沒有提供足夠的模型靈活性來反映出數據的所有特徵；用另一種說法就是這個模型有著高的*偏差(bias)*。\n",
    "\n",
    "> The model on the right attempts to fit a high-order polynomial through the data. Here the model fit has enough flexibility to nearly perfectly account for the fine features in the data, but even though it very accurately describes the training data, its precise form seems to be more reflective of the particular noise properties of the data rather than the intrinsic properties of whatever process generated that data. Such a model is said to *overfit* the data: that is, it has so much model flexibility that the model ends up accounting for random errors as well as the underlying data distribution; another way of saying this is that the model has high *variance*.\n",
    "\n",
    "右邊的模型使用多項式來擬合數據。雖然它很精確的描述了訓練數據，但是這種精確性更多反映了對數據噪聲特徵而不是主要特徵的反映。這樣的模型被稱為是“過擬合(overfit)”：也就是說它有著很好的模型靈活性，甚至反映了數據的隨機誤差；另一種說法就是這個模型有著高的*方差(variance)*。\n",
    "\n",
    "> It is clear that neither of these models is a particularly good fit to the data, but they fail in different ways.To look at this in another light, consider what happens if we use these two models to predict the y-value for some new data.\n",
    "In the following diagrams, the red/lighter points indicate data that is omitted from the training set:\n",
    "\n",
    "很明顯這兩個模型都不是擬合數據的最佳模型，但是它們失敗的地方是不一樣的。從另一個角度來看，如果我們使用這兩個模型來預測一些新數據的y值的話，下圖中的紅色的點代表這數據中從訓練集中分出來的數據點："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/05.03-bias-variance-2.png)\n",
    "[附录中生成图像的代码](06.00-Figure-Code.ipynb#Bias-Variance-Tradeoff-Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The score here is the $R^2$ score, or [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination), which measures how well a model performs relative to a simple mean of the target values. $R^2=1$ indicates a perfect match, $R^2=0$ indicates the model does no better than simply taking the mean of the data, and negative values mean even worse models.\n",
    "From the scores associated with these two models, we can make an observation that holds more generally:\n",
    "\n",
    "這裡使用的評估標準是$R^2$分值，或者稱為[決定係數](https://en.wikipedia.org/wiki/Coefficient_of_determination)，計算的是相對目標值的簡單平均值差距，用來衡量模型預測性能的好方法。 $R^2=1$代表完全複合，$R^2=0$代表模型與簡單取數據平均值沒有區別，負數值代表模型的表現還不如簡單取平均值。從兩個模型的這個分值中，我們可以得到更普遍的結論：\n",
    "\n",
    "- 對於高偏差的模型來說，模型的性能在測試集上與在訓練集上類似。\n",
    "- 對於高方差的模型來說，模型的性能在測試集上比在訓練集上差了非常多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If we imagine that we have some ability to tune the model complexity, we would expect the training score and validation score to behave as illustrated in the following figure:\n",
    "\n",
    "如果想像我們有某種能力能夠調節模型的複雜度，我們可以繪製下面的圖形代表著訓練分數和測試分數的情況：這幅圖像被稱為*驗證曲線*，我們觀察到下面這些關鍵特徵：\n",
    "\n",
    "\n",
    "- 訓練分數在任何地方都比驗證分數要高。這基於：模型在它見過的數據上會比它沒見過的數據上更加擬合。\n",
    "- 對於低複雜度模型（高偏差模型）來說，訓練數據是欠擬合的，這代表著模型既不能很好的預測訓練數據也不能很好的預測未知數據。\n",
    "- 對於非常高複雜度模型（高方法模型）來說，訓練數據是過擬合的，這代表著模型能非常好的預測訓練數據，但是不能很好的預測未知數據。\n",
    "- 對於中間部分來說，驗證曲線有一個最大值。這個點代表著偏差和方差的最佳平衡點。\n",
    "\n",
    "![](figures/05.03-validation-curve.png)\n",
    "[附录中生成图像的代码](06.00-Figure-Code.ipynb#Validation-Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curves in Scikit-Learn\n",
    "\n",
    "### Scikit-Learn中的驗證曲線\n",
    "\n",
    "> Let's look at an example of using cross-validation to compute the validation curve for a class of models.\n",
    "Here we will use a *polynomial regression* model: this is a generalized linear model in which the degree of the polynomial is a tunable parameter.\n",
    "For example, a degree-1 polynomial fits a straight line to the data; for model parameters $a$ and $b$:\n",
    "\n",
    "下面我們來看一個例子說明使用交叉驗證來計算一種模型的驗證曲線。這裡我們將使用*多項式回歸*模型：這是一個廣義的線性模型，其中的多項式的階是可調整的參數。例如，一階的多項式將數據擬合到一條直線上；模型參數有$a$和$b$：\n",
    "\n",
    "$$\n",
    "y = ax + b\n",
    "$$\n",
    "\n",
    "> A degree-3 polynomial fits a cubic curve to the data; for model parameters $a, b, c, d$:\n",
    "\n",
    "一個三階的多項式將數據是配到一條三次方程曲線上；模型參數有$a, b, c, d$：\n",
    "\n",
    "$$\n",
    "y = ax^3 + bx^2 + cx + d\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let's create some data to which we will fit our model:\n",
    "\n",
    "現在我們讓我們創建一些數據來擬合模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_data(N, err=1.0, rseed=1):\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y\n",
    "\n",
    "X, y = make_data(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can now visualize our data, along with polynomial fits of several degrees:\n",
    "\n",
    "然後對數據進行可視化，包含著不同階的多項式匹配結果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set() \n",
    "\n",
    "X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
    "\n",
    "plt.scatter(X.ravel(), y, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The knob controlling model complexity in this case is the degree of the polynomial, which can be any non-negative integer.\n",
    "A useful question to answer is this: what degree of polynomial provides a suitable trade-off between bias (under-fitting) and variance (over-fitting)?\n",
    "\n",
    "這個例子中控制模型複雜度的開關就是多項式的階數，可以使任何非負的整數。這里關鍵的問題是：哪個階的多項式在偏差（欠擬合）和方差（過擬合）之間達到了合適的平衡？\n",
    "\n",
    "> We can make progress in this by visualizing the validation curve for this particular data and model; this can be done straightforwardly using the ``validation_curve`` convenience routine provided by Scikit-Learn.\n",
    "Given a model, data, parameter name, and a range to explore, this function will automatically compute both the training score and validation score across the range:\n",
    "\n",
    "我們還可以進一步將這個特殊的數據和模型的驗證曲線繪製出來；這可以直接通過Scikit-Learn提供的`validation_curve`工具完成。給定模型、數據、參數名稱和一個範圍，這個函數能夠自動計算範圍內所有的訓練分數和驗證分數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (2577646024.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/9q/486czkcn7lv5v0hwbt71twdc0000gn/T/ipykernel_9848/2577646024.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    'polynomialfeatures__degree', degree, cv=7,1)\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "degree = np.arange(0, 21)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y,\n",
    "                                          'polynomialfeatures__degree', degree, cv=7,)\n",
    "\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This shows precisely the qualitative behavior we expect: the training score is everywhere higher than the validation score; the training score is monotonically improving with increased model complexity; and the validation score reaches a maximum before dropping off as the model becomes over-fit.From the validation curve, we can read-off that the optimal trade-off between bias and variance is found for a third-order polynomial; we can compute and display this fit over the original data as follows:\n",
    "\n",
    "從驗證曲線中，我們可以看到最優的偏差和方差平衡出現在三階的多項式附近；我們可以在原始數據上計算並展示這個模型：上圖精確的展示了我們期望的定量行為：訓練分數在任何地方都高於驗證分數；訓練分數是一個單調遞增函數，隨著模型複雜度增加而增加；然而驗證分數在達到最大值後會因為過擬合而開始下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test);\n",
    "plt.axis(lim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that finding this optimal model did not actually require us to compute the training score, but examining the relationship between the training score and validation score can give us useful insight into the performance of the model.\n",
    "\n",
    "請注意尋找這個最優模型並不需要計算訓練分數，但是檢驗訓練分數和驗證分數之間的關係能為我們提供模型性能的內在含義。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves \n",
    "\n",
    "## 學習曲線\n",
    "\n",
    "> One important aspect of model complexity is that the optimal model will generally depend on the size of your training data.\n",
    "For example, let's generate a new dataset with a factor of five more points:\n",
    "\n",
    "對於模型複雜度來說一個重要的相關性是它依賴於訓練數據的規模。例如，我們創建一個數據集，具有5倍數量的樣本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = make_data(200)\n",
    "plt.scatter(X2.ravel(), y2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will duplicate the preceding code to plot the validation curve for this larger dataset; for reference let's over-plot the previous results as well:\n",
    "\n",
    "我們重複前面的代碼來繪製這個大的數據集的驗證曲線；為了對比我們將前面的結果也用虛線畫出來："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "degree = np.arange(21)\n",
    "train_score2, val_score2 = validation_curve(PolynomialRegression(), X2, y2,\n",
    "                                            'polynomialfeatures__degree', degree, cv=7,)\n",
    "\n",
    "plt.plot(degree, np.median(train_score2, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score2, 1), color='red', label='validation score')\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', alpha=0.3, linestyle='dashed')\n",
    "plt.plot(degree, np.median(val_score, 1), color='red', alpha=0.3, linestyle='dashed')\n",
    "plt.legend(loc='lower center')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The solid lines show the new results, while the fainter dashed lines show the results of the previous smaller dataset.\n",
    "It is clear from the validation curve that the larger dataset can support a much more complicated model: the peak here is probably around a degree of 6, but even a degree-20 model is not seriously over-fitting the data—the validation and training scores remain very close.\n",
    "\n",
    "實線展示新的結果，而虛線展示的是前面小數據集的結果。從驗證曲線很明顯看出大的數據集能夠支持更複雜的模型：上圖中的峰值大約出現在階數6的位置上，但是甚至到了20階的多項式模型中，也沒有出現嚴重的過擬合，驗證分數和訓練分數依然很接近。\n",
    "\n",
    "> Thus we see that the behavior of the validation curve has not one but two important inputs: the model complexity and the number of training points.\n",
    "It is often useful to to explore the behavior of the model as a function of the number of training points, which we can do by using increasingly larger subsets of the data to fit our model.\n",
    "A plot of the training/validation score with respect to the size of the training set is known as a *learning curve.*\n",
    "\n",
    "因此我們看到了驗證曲線不止有一個而是有兩個重要的輸入參數：模型複雜度和數據樣本量。研究模型的性能與樣本量之間的關係函數經常也很有幫助，我們可以通過不斷增加數據中用來訓練的子數據集規模來進行研究。繪製一幅訓練/驗證分數隨著訓練集規模變化的圖像被稱為*學習曲線*。\n",
    "\n",
    "> The general behavior we would expect from a learning curve is this:\n",
    "\n",
    "從學習曲線中我們一般可以觀察到下面的結論：\n",
    "\n",
    "- 在小數據集的情況下，一個給定複雜度的模型很可能會*過擬合*：這意味著訓練分數相對來說比較高而驗證分數比較低。\n",
    "- 在大數據集的情況下，一個給定複雜度的模型很可能會*欠擬合*：這意味著訓練分數會下降而驗證分數會上升。\n",
    "- 一個模型應該永遠（除非很偶然的情況下）在訓練集給出比測試集更高的分值：這意味著兩根曲線會一直接近但是不會相交。\n",
    "\n",
    "> With these features in mind, we would expect a learning curve to look qualitatively like that shown in the following figure:\n",
    "\n",
    "有了上述結論，我們預計的學習曲線如下圖："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/05.03-learning-curve.png)\n",
    "[附录中生成图像的代码](06.00-Figure-Code.ipynb#Learning-Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The notable feature of the learning curve is the convergence to a particular score as the number of training samples grows.\n",
    "In particular, once you have enough points that a particular model has converged, *adding more training data will not help you!*\n",
    "The only way to increase model performance in this case is to use another (often more complex) model.\n",
    "\n",
    "學習曲線的一個著名特徵就是當訓練樣本量增加時，兩根曲線會收斂。這意味著，一旦你已經有了足夠的樣本量使得某種模型已經收斂的話，*增加更多的訓練數據不會提供任何幫助*。在這種情況下提升模型性能的唯一方法就是使用另一個（通常更複雜）的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves in Scikit-Learn\n",
    "\n",
    "> Scikit-Learn offers a convenient utility for computing such learning curves from your models; here we will compute a learning curve for our original dataset with a second-order polynomial model and a ninth-order polynomial:\n",
    "\n",
    "Scikit-Learn提供了一個方便的工具來計算模型的學習曲線；下面我們計算我們原始數據集在二階多項式模型和九階多項式模型上的學習曲線："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a valuable diagnostic, because it gives us a visual depiction of how our model responds to increasing training data.\n",
    "In particular, when your learning curve has already converged (i.e., when the training and validation curves are already close to each other) *adding more training data will not significantly improve the fit!*\n",
    "This situation is seen in the left panel, with the learning curve for the degree-2 model.\n",
    "\n",
    "這是一項非常有價值的分析，因為它為我們提供了模型隨著訓練數據增加發生性能變化的可視化展示。而且當你的學習曲線已經收斂時（例如當訓練和驗證曲線已經非常接近的情況下）*增加更多的訓練數據不會顯著的提升擬合度*。這個結論很容易從左圖二階模型的學習曲線中獲得。\n",
    "\n",
    "> The only way to increase the converged score is to use a different (usually more complicated) model.\n",
    "We see this in the right panel: by moving to a much more complicated model, we increase the score of convergence (indicated by the dashed line), but at the expense of higher model variance (indicated by the difference between the training and validation scores).\n",
    "If we were to add even more data points, the learning curve for the more complicated model would eventually converge.\n",
    "\n",
    "要提升已經收斂的學習曲線的性能唯一方法就是使用一個不同的（通常更複雜的）模型。我們可以從右圖中看到：當使用了複雜的多的模型後，我們將收斂的分數值（使用虛線表示）提升了，付出的代價是更高的模型方差（圖中訓練曲線和驗證曲線的間距）。如果我們繼續增加更多的樣本，更複雜模型的學習曲線最終也會收斂。\n",
    "\n",
    "> Plotting a learning curve for your particular choice of model and dataset can help you to make this type of decision about how to move forward in improving your analysis.\n",
    "\n",
    "繪製模型和數據集的學習曲線能幫助你作出進一步改善性能的決定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "for i, degree in enumerate([2, 9]):\n",
    "    N, train_lc, val_lc = learning_curve(PolynomialRegression(degree),\n",
    "                                         X, y, cv=7,\n",
    "                                         train_sizes=np.linspace(0.3, 1, 25))\n",
    "\n",
    "    ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score')\n",
    "    ax[i].plot(N, np.mean(val_lc, 1), color='red', label='validation score')\n",
    "    ax[i].hlines(np.mean([train_lc[-1], val_lc[-1]]), N[0], N[-1],\n",
    "                 color='gray', linestyle='dashed')\n",
    "\n",
    "    ax[i].set_ylim(0, 1)\n",
    "    ax[i].set_xlim(N[0], N[-1])\n",
    "    ax[i].set_xlabel('training size')\n",
    "    ax[i].set_ylabel('score')\n",
    "    ax[i].set_title('degree = {0}'.format(degree), size=14)\n",
    "    ax[i].legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation in Practice: Grid Search\n",
    "\n",
    "## 驗證實踐：網格搜索\n",
    "\n",
    "> In practice, models generally have more than one knob to turn, and thus plots of validation and learning curves change from lines to multi-dimensional surfaces.\n",
    "In these cases, such visualizations are difficult and we would rather simply find the particular model that maximizes the validation score.\n",
    "Scikit-Learn provides automated tools to do this in the grid search module.\n",
    "Here is an example of using grid search to find the optimal polynomial model.\n",
    "We will explore a three-dimensional grid of model features; namely the polynomial degree, the flag telling us whether to fit the intercept, and the flag telling us whether to normalize the problem.\n",
    "This can be set up using Scikit-Learn's ``GridSearchCV`` meta-estimator:\n",
    "\n",
    "在實踐中，模型通常有多於一個開關進行調節，因此前面關於驗證曲線和學習曲線的二維線條就會變成多維平面。在這些情況下，要將它可視化出來是很困難的，並且我們更希望簡單的找到特定模型能最大化驗證分數。Scikit-Learn提供了自動化的工具來完成這項任務，它們在網格搜索模塊中。下面是一個使用網格搜索找到最優多項式模型的例子。我們會探索模型特徵的一個三維網格；包括多項式階數，一個是否擬合截距的標誌和一個是否歸一化問題的標誌。這可以通過Scikit-Learn的`GridSearchCV`元評估器來設置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree': np.arange(21),\n",
    "              'linearregression__fit_intercept': [True, False],\n",
    "              'linearregression__normalize': [True, False]}\n",
    "\n",
    "grid = GridSearchCV(PolynomialRegression(), param_grid, cv=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that like a normal estimator, this has not yet been applied to any data.\n",
    "Calling the ``fit()`` method will fit the model at each grid point, keeping track of the scores along the way:\n",
    "\n",
    "網格搜索模型和普通模型一樣，實例化後還未應用到任何數據上。通過調用`fit()`方法會將模型的每個網格點擬合到數據上，同時過程中保存了驗證的分數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that this is fit, we can ask for the best parameters as follows:\n",
    "\n",
    "擬合完後，我們可以使用代碼來獲得最佳參數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally, if we wish, we can use the best model and show the fit to our data using code from before:\n",
    "\n",
    "最終，需要的話，我們可以使用代碼將最佳模型、數據及它們的擬合情況繪製出來："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "\n",
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = model.fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test);\n",
    "plt.axis(lim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The grid search provides many more options, including the ability to specify a custom scoring function, to parallelize the computations, to do randomized searches, and more.\n",
    "For information, see the examples in [In-Depth: Kernel Density Estimation](05.13-Kernel-Density-Estimation.ipynb) and [Feature Engineering: Working with Images](05.14-Image-Features.ipynb), or refer to Scikit-Learn's [grid search documentation](http://Scikit-Learn.org/stable/modules/grid_search.html).\n",
    "\n",
    "網格搜索提供很多其他參數，包括指定自定義的評分函數，並行化計算和執行隨機搜索等等。需要更多信息，參見[深入：核密度估計](05.13-Kernel-Density-Estimation.ipynb)和[特徵工程](05.14-Image-Features.ipynb)，或者參考Scikit-Learn的[網格搜索在線文檔](http://Scikit-Learn.org/stable/modules/grid_search.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "## 總結\n",
    "\n",
    "> In this section, we have begun to explore the concept of model validation and hyperparameter optimization, focusing on intuitive aspects of the bias–variance trade-off and how it comes into play when fitting models to data.\n",
    "In particular, we found that the use of a validation set or cross-validation approach is *vital* when tuning parameters in order to avoid over-fitting for more complex/flexible models.\n",
    "\n",
    "在本節中，我們開始探討模型驗證和超參數優化的概念，聚焦在偏差方差權衡的直觀概念和它在模型擬合數據時扮演的角色。特別是，我們強調使用測試集驗證和交叉驗證方法的重要性，當在復雜/靈活模型中調節參數時要避免過擬合。\n",
    "\n",
    "> In later sections, we will discuss the details of particularly useful models, and throughout will talk about what tuning is available for these models and how these free parameters affect model complexity.\n",
    "Keep the lessons of this section in mind as you read on and learn about these machine learning approaches!\n",
    "\n",
    "在後續章節中，我們會討論每種模型的細節，並在過程中介紹這些模型可以調節哪些參數以及這些參數如何影響模型複雜度。請將本節的內容牢記，當你在後面繼續學習機器學習方法的時候，本節內容會提供重要的幫助。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Scikit-Learn简介](05.02-Introducing-Scikit-Learn.ipynb) | [目录](Index.ipynb) | [特征工程](05.04-Feature-Engineering.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/wangyingsm/Python-Data-Science-Handbook/blob/master/notebooks/05.03-Hyperparameters-and-Model-Validation.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
